[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ADRF User Guide",
    "section": "",
    "text": "1 Welcome\nWelcome to the ADRF User Guide.\nThis guide provides essential information for accessing, using, and collaborating within the Administrative Data Research Facility (ADRF). Whether you’re onboarding or already deep into research, this guide helps ensure you’re working safely, efficiently, and in accordance with ADRF policies.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ADRF User Guide</span>"
    ]
  },
  {
    "objectID": "index.html#what-youll-find",
    "href": "index.html#what-youll-find",
    "title": "ADRF User Guide",
    "section": "What You’ll Find",
    "text": "What You’ll Find\n\nHow to request and manage ADRF access\nCollaboration tools and workspace setup\nData querying and dashboard guidance\nExport procedures and disclosure rules\nFAQs and support contact info\n\nUse the sidebar to navigate through the chapters.\n\nFor questions or assistance, email support@coleridgeinitiative.org or visit our GitHub repository.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ADRF User Guide</span>"
    ]
  },
  {
    "objectID": "00-cover.html",
    "href": "00-cover.html",
    "title": "2  ADRF User Guide",
    "section": "",
    "text": "Navigation\nA detailed guide to help users navigate and use the Coleridge Initiative’s Administrative Data Research Facility (ADRF) effectively.\nLast Modified: 03/21/2025",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>ADRF User Guide</span>"
    ]
  },
  {
    "objectID": "00-cover.html#navigation",
    "href": "00-cover.html#navigation",
    "title": "2  ADRF User Guide",
    "section": "",
    "text": "Click on any of the sections for detailed guidance.\nYou can always return to this page by clicking on “Back to Home” at the bottom of each section page.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>ADRF User Guide</span>"
    ]
  },
  {
    "objectID": "00-cover.html#table-of-contents",
    "href": "00-cover.html#table-of-contents",
    "title": "2  ADRF User Guide",
    "section": "Table of Contents",
    "text": "Table of Contents\n\nIntroduction\n\nObtaining ADRF Access\n\nOnboarding Modules and Security Training\nHow to Access and Use Your Project Workspace\nHow to Access Data\nWhere to Do Your Work\nHow to Work Collaboratively in the ADRF\nHow to Export Output from the ADRF\nDo’s and Don’ts for Discussing Data Hosted in the ADRF\nAdding Additional Packages in R/Python\nRedshift Querying Guide\nAccessing ADRF Dashboards\nFAQ",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>ADRF User Guide</span>"
    ]
  },
  {
    "objectID": "01-intro.html",
    "href": "01-intro.html",
    "title": "3  1 Introduction",
    "section": "",
    "text": "Topics\nWelcome to the Coleridge Initiative’s Administrative Data Research Facility, or “ADRF” user guide. This is a living document intended to show new ADRF users how to use the platform for common tasks.\nIf you have any questions, please reach out to us at support@coleridgeinitiative.org",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>1 Introduction</span>"
    ]
  },
  {
    "objectID": "01-intro.html#topics",
    "href": "01-intro.html#topics",
    "title": "3  1 Introduction",
    "section": "",
    "text": "About the Coleridge Initiative\nAbout the Administrative Data Research Facility\nThe Five Safes Security Framework",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>1 Introduction</span>"
    ]
  },
  {
    "objectID": "01-intro.html#about-the-coleridge-initiative",
    "href": "01-intro.html#about-the-coleridge-initiative",
    "title": "3  1 Introduction",
    "section": "About the Coleridge Initiative",
    "text": "About the Coleridge Initiative\nThe Coleridge Initiative’s mission is to improve the access, usability, and impact of data for public policy by fostering collaboration between government agencies, researchers, and other stakeholders. It aims to create a data ecosystem where government data can be more effectively used to inform evidence-based decision-making, policy development, and research.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>1 Introduction</span>"
    ]
  },
  {
    "objectID": "01-intro.html#about-the-administrative-data-research-facility",
    "href": "01-intro.html#about-the-administrative-data-research-facility",
    "title": "3  1 Introduction",
    "section": "About the Administrative Data Research Facility",
    "text": "About the Administrative Data Research Facility\nThe Administrative Data Research Facility (ADRF) is a platform provided by the Coleridge Initiative that enables researchers to access and analyze administrative data from government agencies securely and efficiently. It offers a secure computing environment where researchers can work with sensitive data while ensuring privacy and confidentiality. The ADRF provides tools and infrastructure for data integration, analysis, and visualization, allowing researchers to conduct rigorous and reproducible studies using large-scale administrative datasets. By facilitating access to valuable data resources and promoting collaboration between researchers, government agencies, and other stakeholders, the ADRF supports evidence-based policymaking and advances research in fields such as public health, education, labor economics, and social policy.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>1 Introduction</span>"
    ]
  },
  {
    "objectID": "01-intro.html#the-five-safes-security-framework",
    "href": "01-intro.html#the-five-safes-security-framework",
    "title": "3  1 Introduction",
    "section": "The Five Safes Security Framework",
    "text": "The Five Safes Security Framework\nThe ADRF follows the Five Safes Framework, a data management framework commonly used in government agencies, to ensure the safe use of sensitive and confidential data assets. It considers five dimensions in making data-related safety and security decisions: Safe Projects, Safe People, Safe Settings, Safe Data, and Safe Exports.\n\n\n\nThe Five Safes Security Framework\n\n\n\nSafe Projects - The ADRF contains only agency approved projects that have been proposed and agreed upon by project and dataset stewards. Only approved projects are housed within ADRF, only approved individuals are granted access to a given project, and project environments are kept separated from each other. These approved projects require signed agreements and only approved users can access the project workspaces within the platform.\nSafe People - Only approved researchers are permitted to access project workspaces and related resources. Each individual with approved access must complete security training, agree to the ADRF terms of use, and sign relevant data use agreements. Individuals must authenticate to gain access to the remote platform and all ADRF activity is monitored.\nSafe Settings - The ADRF is designed to provide secure methods of data transfer for agency micro-data, specifically data that includes Personally Identifiable Information. Only agency identified and authorized personnel are invited to perform data transfers.\nSafe Data - Before transmission to ADRF, all data with personally identifiable or other sensitive information is hashed, and an online data stewardship application provides data stewards with information on who is accessing their data, how it is being accessed, what projects employ it, the characteristics of each data asset, and the status of user agreements.\nSafe Exports - Users are prevented from unauthorized removal of any information within the secure environment.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>1 Introduction</span>"
    ]
  },
  {
    "objectID": "02-access.html",
    "href": "02-access.html",
    "title": "4  2 Obtaining ADRF Access",
    "section": "",
    "text": "Topics",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>2 Obtaining ADRF Access</span>"
    ]
  },
  {
    "objectID": "02-access.html#topics",
    "href": "02-access.html#topics",
    "title": "4  2 Obtaining ADRF Access",
    "section": "",
    "text": "Account Setup\nObtaining ADRF Access\nAccount Registration and Onboarding\nMore Information",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>2 Obtaining ADRF Access</span>"
    ]
  },
  {
    "objectID": "02-access.html#account-setup",
    "href": "02-access.html#account-setup",
    "title": "4  2 Obtaining ADRF Access",
    "section": "Account Setup",
    "text": "Account Setup\n\nAgency-affiliated researcher. If you are an agency-affiliated researcher, your agency will set up an ADRF account for you.\nIndividual part of a training program. If you are part of a training program, the Coleridge Initiative team will create an account for you once you have been accepted into the program.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>2 Obtaining ADRF Access</span>"
    ]
  },
  {
    "objectID": "02-access.html#obtaining-adrf-access",
    "href": "02-access.html#obtaining-adrf-access",
    "title": "4  2 Obtaining ADRF Access",
    "section": "Obtaining ADRF Access",
    "text": "Obtaining ADRF Access\n\nAgency-affiliated researcher. If you are an agency-affiliated researcher using an agency-sponsored account, you will be granted ADRF access once you complete your onboarding tasks and required data access agreements. If you are a self-paying agency-affiliated researcher, your ADRF access is conditional on receipt of payment. If your institution of Office of Sponsored Programs will be submitting payment on your behalf, please be aware of potential access delays. Whenever possible, the Coleridge Initiative advises paying with a personal credit card or institutional payment card and using the generated invoice to request reimbursement.\nIndividual part of a training program. If you are part of a training program, you will be granted ADRF access once you complete your onboarding tasks and required data access agreements.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>2 Obtaining ADRF Access</span>"
    ]
  },
  {
    "objectID": "02-access.html#account-registration-and-onboarding-tasks",
    "href": "02-access.html#account-registration-and-onboarding-tasks",
    "title": "4  2 Obtaining ADRF Access",
    "section": "Account Registration and Onboarding Tasks",
    "text": "Account Registration and Onboarding Tasks\n\nYou will receive an email invitation to activate your account. The email will come from http://okta.com, so please make sure that it doesn’t get caught in your email spam filter. Follow the steps outlined in the email to set up your password and your multi-factor authentication preferences. Clink on the link below to watch a video walking through the steps.\nAfter activating your account, you will be logged in to the ADRF Applications page. Proceed to the Management Portal by clicking on the icon.\nIn the Management Portal, you will notice a “Onboarding Tasks” section within “Admin Tasks” with a number of items you will need to complete before you can gain access to the project space. Refer to the next section for details about the onboarding process.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>2 Obtaining ADRF Access</span>"
    ]
  },
  {
    "objectID": "02-access.html#more-information",
    "href": "02-access.html#more-information",
    "title": "4  2 Obtaining ADRF Access",
    "section": "More Information",
    "text": "More Information\nIf you have any questions, please contact support@coleridgeinitiative.org.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>2 Obtaining ADRF Access</span>"
    ]
  },
  {
    "objectID": "03-onboarding.html",
    "href": "03-onboarding.html",
    "title": "5  3 Onboarding Modules and Security Training",
    "section": "",
    "text": "Topics",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>3 Onboarding Modules and Security Training</span>"
    ]
  },
  {
    "objectID": "03-onboarding.html#topics",
    "href": "03-onboarding.html#topics",
    "title": "5  3 Onboarding Modules and Security Training",
    "section": "",
    "text": "Management Portal\nAccessing the Onboarding Tasks\nSigning the ADRF Terms of Use Agreement\nWatching the Security Training Video\nComplete the Security Training Quiz",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>3 Onboarding Modules and Security Training</span>"
    ]
  },
  {
    "objectID": "03-onboarding.html#management-portal",
    "href": "03-onboarding.html#management-portal",
    "title": "5  3 Onboarding Modules and Security Training",
    "section": "Management Portal",
    "text": "Management Portal\nThe Management Portal web-based application is positioned primarily as the management and monitoring console for project and data stewards. It provides detailed insight on project configurations, user activity, user onboarding status, and overall cost of a project on the ADRF. We focus on four primary pillars of information a Project/Data Steward most often focuses on: - People – Who are the members of projects, how often do they use the ADRF, what exports have they requested and their status, estimated cost per person/project for current month and for the project since inception, and detailed usage metrics. - Projects – Details of project start/end dates, abstract description, number of members onboarded and pending, and resources the project has access to (i.e. datasets, etc). - Datasets – Description of the dataset, location on the ADRF (database or file system), size, name of the data steward(s), and the link to Enterprise Data Catalog (Informatica) describing the dataset and metadata. - Agreements – What agreements are related to these projects, indication of each member’s signing status, members pending signature, and term (dates) covered by the agreement(s).\nAs mentioned, the Management Portal application will track your ADRF usage. The protal will also consolidate your ADRF Terms of Use, Security Training Quiz, and Security Training Video into one place. In order to complete ADRF onboarding, all three of the mentioned tasks are to be completed by the user (researcher). To access the Management Portal, log in using your credentials at https://adrf.okta.com and click on the ADRF Management Portal icon:\n\n\n\nADRF Management Portal Icon\n\n\nOnce inside the Management Portal, you have access to your personal workspace sessions statistics along with admin tasks such as the three onboarding tasks and password management. See the example below:\n\n\n\nManagement Portal Insights Page",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>3 Onboarding Modules and Security Training</span>"
    ]
  },
  {
    "objectID": "03-onboarding.html#accessing-the-onboarding-tasks",
    "href": "03-onboarding.html#accessing-the-onboarding-tasks",
    "title": "5  3 Onboarding Modules and Security Training",
    "section": "Accessing the Onboarding Tasks",
    "text": "Accessing the Onboarding Tasks\nTo gain access to your ADRF project workspace, you must first complete 3 required ADRF onboarding tasks: 1. Signing the ADRF Terms of Use agreement. Users must comply with the Terms of Use when working in the ADRF. The Agreement covers rules of behavior within ADRF and guidelines for discussing ADRF content prior to passing disclosure review. It asks users to agree to a series of principles governing dataset use, behavior, and data export procedures, and to acknowledge the consequences of violating the Terms. 2. Completing security awareness training. Users will get access to a security awareness video and should confirm that they have reviewed the video. The video covers security content that is then assessed during the security awareness quiz. 3. Passing the security awareness quiz. The security awareness quiz consists of a set of 6 questions. Users must achieve a score 5 out of 6 to pass the quiz. Unsuccessful users can retake the quiz to achieve a passing score.\nFollow the steps below to access the ADRF Onboarding Tasks: 1. Log in to the Management Portal\n\nClick on “Admin Tasks” in the left navigation menu.\n\n\n\n\nClick on ‘Admin Tasks’ in the left navigation menu\n\n\n\nClick on “Complete Onboarding”.\n\n\n\n\nClick on ‘Complete Onboarding’\n\n\n\nThis will load the Onboarding Tasks window.\n\n\n\n\nOnboarding Tasks window\n\n\n\nClick on each individual task to complete it.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>3 Onboarding Modules and Security Training</span>"
    ]
  },
  {
    "objectID": "03-onboarding.html#signing-the-adrf-terms-of-use-agreement",
    "href": "03-onboarding.html#signing-the-adrf-terms-of-use-agreement",
    "title": "5  3 Onboarding Modules and Security Training",
    "section": "Signing the ADRF Terms of Use Agreement",
    "text": "Signing the ADRF Terms of Use Agreement\nThe Terms of Use need to be completed before you are given access to the data and project space inside the ADRF. To complete ADRF Terms of Use, complete the following steps:\n\nClick on the “Terms of Use” tile.\n\n\n\n\nTerms of Use Tile\n\n\n\nClick on “Sign with DocuSign”\n\n\n\n\nSign with DocuSign\n\n\n\nYou will then be redirected to the DocuSign signing page. Click “Continue” on the upper right corner.\n\n\n\n\nClick Continue\n\n\n\nClick “Start” to begin.\n\n\n\n\nClick Start to begin\n\n\n\nIf you have already configured a signature, click on the yellow “Sign” button to apply it. Otherwise, follow the prompts to configure your electronic signature.\n\n\n\n\nClick the yellow Sign button to apply your signature\n\n\n\nOnce the signature is applied, click “Finish”.\n\n\n\n\nClick Finish\n\n\nYou will then be redirected back to the management portal; and the “Terms of Use” task will be marked as completed.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>3 Onboarding Modules and Security Training</span>"
    ]
  },
  {
    "objectID": "03-onboarding.html#watching-the-security-training-video",
    "href": "03-onboarding.html#watching-the-security-training-video",
    "title": "5  3 Onboarding Modules and Security Training",
    "section": "Watching the Security Training Video",
    "text": "Watching the Security Training Video\nYou will also need to watch the ADRF Security Training Video.\n\n\n\nADRF Security Training Video\n\n\nTo complete this portion of the ADRF Security Training, do the following:\n\nClick on the “Security Training Video” tile to load the player and then click play.\nOnce you have watched the video in its entirety, click on the “Mark as Complete” button to complete the task. Note: the “MARK AS COMPLETE” button will not be enabled until at least 5 minutes have passed since the start of the video.\nClick on the back arrow in the upper right corner to return to the main tasks panel.\nThe training video section will now be marked as completed.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>3 Onboarding Modules and Security Training</span>"
    ]
  },
  {
    "objectID": "03-onboarding.html#complete-the-security-training-quiz",
    "href": "03-onboarding.html#complete-the-security-training-quiz",
    "title": "5  3 Onboarding Modules and Security Training",
    "section": "Complete the Security Training Quiz",
    "text": "Complete the Security Training Quiz\nThe Security Training Quiz needs to be completed after the Security Training Video. To complete the training, complete the following steps:\n\nClick on the “Security Quiz” tile to load the quiz.\n\n\n\n\nClick on the Security Quiz tile\n\n\n\nAnswer the questions and click on the “SUBMIT RESPONSE” button. You must answer at least four of the questions correctly to complete this task.\n\n\n\n\nClick on the Submit Response button\n\n\n\nYou will be automatically redirected to the main task panel once the questionnaire has been successfully completed. And the “Security Quiz” will be marked as completed.\n\n\n\n\nSecurity Quiz Complete",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>3 Onboarding Modules and Security Training</span>"
    ]
  },
  {
    "objectID": "04-access-and-use.html",
    "href": "04-access-and-use.html",
    "title": "6  4 How to Access and Use Your Project Workspace",
    "section": "",
    "text": "Topics\nA project workspace is a secure, isolated virtual environment in the ADRF within which an approved set of users can access a defined number of agency datasets. The project workspace is designed to allow approved researchers to access, analyze, and manipulate specific datasets relevant to their approved projects while maintaining strict data confidentiality and integrity.\nProject workspaces in the ADRF are isolated from each other. Even if a person is granted access to two project workspaces, the user can not access or copy files from one into the other. This is important because the two project workspaces might have access to different datasets.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>4 How to Access and Use Your Project Workspace</span>"
    ]
  },
  {
    "objectID": "04-access-and-use.html#topics",
    "href": "04-access-and-use.html#topics",
    "title": "6  4 How to Access and Use Your Project Workspace",
    "section": "",
    "text": "Logging into and Logging out of the ADRF\nVirtual Desktop Environment\nSoftware in the ADRF",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>4 How to Access and Use Your Project Workspace</span>"
    ]
  },
  {
    "objectID": "04-access-and-use.html#logging-into-and-logging-out-of-the-adrf",
    "href": "04-access-and-use.html#logging-into-and-logging-out-of-the-adrf",
    "title": "6  4 How to Access and Use Your Project Workspace",
    "section": "Logging into and Logging out of the ADRF",
    "text": "Logging into and Logging out of the ADRF\nThis video linked below runs through the necessary steps for logging into and logging out of the ADRF.\nTo watch the video, right-click the image below and choose “Open link in new tab” (by right-cicking, you will avoid leaving this page).\n](https://www.youtube.com/watch?v=_-AE_iOyF9w)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>4 How to Access and Use Your Project Workspace</span>"
    ]
  },
  {
    "objectID": "04-access-and-use.html#virtual-desktop-environment",
    "href": "04-access-and-use.html#virtual-desktop-environment",
    "title": "6  4 How to Access and Use Your Project Workspace",
    "section": "Virtual Desktop Environment",
    "text": "Virtual Desktop Environment\n\nWhat is a VDE?\nA virtual desktop environment (VDE) allows you to interact with a remote system as if it were your own personal computer. The majority of your standard desktop functions are available, but the programs, data, and permissions are all controlled by the remote administrator (Coleridge Initiative). Thus, you will be working in a familiar environment while accessing protected data, programs, and systems that would otherwise be difficult to distribute. The ADRF uses a standard Windows environment (Windows Server) and provides a variety of software packages to conduct your analysis. For more on Windows capabilities, see the section on Windows Settings.\n\n\n\nVirtual Desktop Environment\n\n\n\n\nTemporary Nature of the Environment\nWhile the environment is similar to that on your home computer (for Windows users), there are a handful of key differences. The first is that the environment is temporary in nature. This means that if you are not using it for a prolonged period of time (default is four hours but can vary by project), running programs will stop running and the information stored in temporary locations will be deleted. You will receive on on-screen message before any sessions are terminated. For more on safe, non-temporary storage locations in the ADRF, see the section on Storing Analytic Results.\nGiven the temporary nature of the ADRF, it is crucial to make sure that your work is saved—and saved in an appropriate location. Once this is complete and you are finished working, make sure that you log out of the ADRF instead of closing the window. To do this, click the rightmost icon on the top taskbar to open up the dropdown menu and select End Session. You will be prompted to double-check that your work is saved prior to ending your session and confirm that you want to end your session.\n\n\nModifying the Environment\n\nEstablishing Personal Folders\nEstablishing your own personal folders is one of the simplest, yet most important, steps to take when setting up your environment. As we note in the section on Storing Analytic Results, the two possible places to store your analytic results or files are in either the U: drive or the P: drive.\nYou will find your personal folder in the U: drive. The folder name will include your Firstname and Lastname, and may additionally include your project workspace number. This is a personal workspace that only you can access in the ADRF.\n\nThe U: Drive and the P: Drive\nThe U: drive is your user drive; it’s where you will store any files you are working on. Only the user will have access to the U: drive. For example, if user A wants to share information with user B who is on the same project, user A will need to save files to a P: drive folder and not folders in their U: drive since user B will not be able to access user A’s U: drive.\nThe P: drive is the project drive, which will be used to house project-specific folders. Thus, you and other collaborators on the same project will be able to save files to project drive folders.\nBoth the U: drive and P: drive have defined resource limitations of 150GB. When the workspace exceeds these limits, users will not be able to create new files or save data. The ADRF will not alert users when they approach on 150GB used. Users can check their current usage by right clicking on the user folder and clicking on properties.\n\n\n\nOther Modifications\nThe top taskbar contains shortcuts to the command prompt, multiple desktop windows, a temporary folder, settings, full-screen view, and toggling multiple monitors.\n\n\n\nTaskbar\n\n\n\n\n\nWindows Settings\nYour desktop will look familiar if you are a Windows user. You will have icons for quick access to programs or browsers on your desktop. The windows icon on the bottom left side of the screen will open up a menu of programs, folders, and other tools, much as you would see on your own desktop. You will have access to PowerShell and several customization settings (e.g., remove bottom taskbar).\n\n\n\nDesktop",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>4 How to Access and Use Your Project Workspace</span>"
    ]
  },
  {
    "objectID": "04-access-and-use.html#software-in-the-adrf",
    "href": "04-access-and-use.html#software-in-the-adrf",
    "title": "6  4 How to Access and Use Your Project Workspace",
    "section": "Software in the ADRF",
    "text": "Software in the ADRF\n\nJupyterLab\nJupyterLab provides flexible building blocks for interactive, exploratory computing. While JupyterLab has many features found in traditional integrated development environments (IDEs), it remains focused on interactive, exploratory computing. For more on JupyterLab, see the interface documentation.\nThe JupyterLab interface on the ADRF consists of a main work area containing tabs of documents and activities, a collapsible left sidebar, and a menu bar. The left sidebar contains a file browser, the list of running terminals and kernels, the table of contents, and the extension manager. \nWhen using Jupyter Notebooks, make sure that all your work is saved to your U: drive and the correct director within the U: drive. You can “nd the active directory by reading the path displayed in the file browser. By default, JupyterLab opens with your U: drive as the base directory. Below, the folder icon in the white box is my user folder (not displayed, but titled Firstname.Lastname; you will have already set up your folder) and subfolder WDQI.\n\n\n\nMake sure your work is saved to your U: drive\n\n\n\nNotebooks\nJupyter Notebooks are documents that combine live runnable code with narrative text (Markdown), equations (LaTeX), images, interactive visualizations, and other rich output. You can create a notebook by clicking the blue + button in the file browser and then selecting a kernel (R, Python3, Stata) in the Launcher tab. For more information on getting started with Jupyter Notebooks, see JupyterLab Notebook documentation.\n\n\nAccessing Stored Data from a Notebook\nA common question is how to access stored data while writing to and using a Jupyter Notebook. Data in the ADRF are stored in a database using Microsoft SQL Server. For more information on how to access stored data in the ADRF based on choice of program (Python, R, Stata), see the section on Accessing Your Data.\n\n\n\nPython 3\nPython is a general-purpose programming language. You can access Python in a multitude of ways:\n\nThrough JupyterLab. This is the recommended way to access Python since it has packages installed and available, and an execution environment for testing and running code (as well as a place to write and save code). Open JupyterLab and make sure your directory is set appropriately in the “le browser. Once there, in your new Launcher window, click the Python 3 icon.\n\n\n\n\nJupyterLab\n\n\n\nThrough the start menu (windows icon). Type in Python. A desktop app called Python 3.7 (64-bit) will populate a window where you can begin programming.\n\n\n\n\nStart menu\n\n\n\nThrough the command prompt in the top taskbar. Once the command prompt window is open, type in python.\n\n\n\n\nCommand Prompt\n\n\n\nThrough Pycharm\n\n\n\n\nPycharm\n\n\n\n\nR\nR is a general-purpose programming language. You may access R in one of three ways:\n\nThrough RStudio. This is an integrated development environment (IDE) for R. You can run R code, display variables, debug R code, do inline visualizations, and more. Open RStudio through the desktop shortcut, or type RStudio in the start menu.\nThrough JupyterLab. Open JupyterLab and make sure your directory is set appropriately in the file browser. Once there, in your new Launcher window, click the R icon.\n\n\n\n\nUsing R in JuypterLab\n\n\n\nThrough the R GUI (graphical user interface). Type R in the search bar and click to open the RGui.\n\n\n\nStata\nStata is a general-purpose statistical so#ware package. Stata can be accessed through the desktop shortcut StataMP 16 or by searching for it using the search or menu bar, or through JupyterLab.\n\n\nDBeaver\nDBeaver is a universal tool for querying, editing, and managing data stored in Redshift databases. The ADRF stores data using AWS Redshift Server. DBeaver can be accessed through the desktop shortcut DBeaver or by looking it up using the search bar.\nOnce open, you will need to connect to a Redshift server. Please follow the directions in the Redshift Querying Guide to connect to the appropriate server.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>4 How to Access and Use Your Project Workspace</span>"
    ]
  },
  {
    "objectID": "05-access-data.html",
    "href": "05-access-data.html",
    "title": "7  5 How to Access Data",
    "section": "",
    "text": "Topics\nThis section provides information on how to locate the secure data you’ve been approved to access in the ADRF.\nThe ADRF offers both unstructured and structured data storage. Data stored in databases are located in the ADRF’s structured data storage. Other forms of data, such as flat files, CSVs, documentation, etc. are stored in the ADRF’s unstructured data storage.\nExternal Data and Code: Please note that importing of external data and code is restricted to only Coleridge staff. Given the secure and protected environment provided by the ADRF, all code, data, and packages that are coming from outside of the ADRF must be carefully vetted to prevent leaks, disclosure, or unauthorized access. This means that there is no direct method for uploading data or code from your system to the ADRF. Please contact support@coleridgeinitiative.org for any questions or assistance on importing your own code, data, or packages.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>5 How to Access Data</span>"
    ]
  },
  {
    "objectID": "05-access-data.html#topics",
    "href": "05-access-data.html#topics",
    "title": "7  5 How to Access Data",
    "section": "",
    "text": "Accessing data stored in unstructured data storage\nAccessing data stored in structured data storage",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>5 How to Access Data</span>"
    ]
  },
  {
    "objectID": "05-access-data.html#accessing-data-stored-in-unstructured-data-storage",
    "href": "05-access-data.html#accessing-data-stored-in-unstructured-data-storage",
    "title": "7  5 How to Access Data",
    "section": "Accessing data stored in unstructured data storage",
    "text": "Accessing data stored in unstructured data storage\nUnstructured data, such as CSVs, Stata DTAs, SAS data, are stored in the “G” drive. Project teams will have read-only access to the data folders in this drive that they have been approved to access.\nThe G: Drive is located in the ADRF’s file system. You can find it by going to the Folder icon in the Windows Task Bar.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>5 How to Access Data</span>"
    ]
  },
  {
    "objectID": "05-access-data.html#accessing-data-stored-in-structured-data-storage",
    "href": "05-access-data.html#accessing-data-stored-in-structured-data-storage",
    "title": "7  5 How to Access Data",
    "section": "Accessing data stored in structured data storage",
    "text": "Accessing data stored in structured data storage\nStructured data, or data that are stored in relational databases, are stored in AWS Redshift, an MPP platform that is built on SQL and is specifically designed to handle larger data assets. Users access structured data either through DBeaver – the ADRF’s Database Access tool – or by porting directly to Redshift through their preferred statistical package (like R, or Python).\nFor detailed instructions on how to access data in structed data storage, please see the ADRF’s Redshift Querying Guide",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>5 How to Access Data</span>"
    ]
  },
  {
    "objectID": "06-where-to-work.html",
    "href": "06-where-to-work.html",
    "title": "8  6 Where to Do Your Work",
    "section": "",
    "text": "Topics\nThe sensitive data that you have been approved to access will either be stored in the ADRF’s structured or unstructured stroage locations (see How to Access Data](05-access-data.md).",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>6 Where to Do Your Work</span>"
    ]
  },
  {
    "objectID": "06-where-to-work.html#topics",
    "href": "06-where-to-work.html#topics",
    "title": "8  6 Where to Do Your Work",
    "section": "",
    "text": "Eligible locations to do your work\nIneligible locations to do your work\nStorage Size Restrictions and Best Practices",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>6 Where to Do Your Work</span>"
    ]
  },
  {
    "objectID": "06-where-to-work.html#eligible-locations-to-do-your-work",
    "href": "06-where-to-work.html#eligible-locations-to-do-your-work",
    "title": "8  6 Where to Do Your Work",
    "section": "Eligible locations to do your work",
    "text": "Eligible locations to do your work\nYou can perform your approved project work in one of the following locations in the ADRF: - User Drive - Project Drive - PR schema\n\nUser Drive\nThe U: drive is your user drive; it’s where you will store any files you are working on. Only the user will have access to the U: drive. For example, if user A wants to share information with user B who is on the same project, user A will need to save files to a P: drive folder and not folders in their U: drive since user B will not be able to access user A’s U: drive.\n\n\nProject Drive\nThe P: drive also allows permanent storage. This drive is accessible by anyone on the same project, but not across projects. This is the only drive outside of the user drive where saved files will not be erased after logging out of the ADRF.\n\n\nPR Schema\nEach project will have a project-specific database created. All members of the project will have read and write permissions for data and may also create their own objects (tables, etc.). The project databases are prefixed with pr-.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>6 Where to Do Your Work</span>"
    ]
  },
  {
    "objectID": "06-where-to-work.html#ineligible-locations-to-do-your-work",
    "href": "06-where-to-work.html#ineligible-locations-to-do-your-work",
    "title": "8  6 Where to Do Your Work",
    "section": "Ineligible locations to do your work",
    "text": "Ineligible locations to do your work\nThe G: drive (data), the L: drive (Libs), and the desktop are not eligible for long-term file storing. You won’t have permissions to write to either the G: drive or the L: drive. The desktop will function only as temporary storage—as soon as a user is logged out of the ADRF, your desktop will be cleared. Additionally, since Wi-Fi connectivity can be imperfect, desktop storage for any amount of time is not recommended.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>6 Where to Do Your Work</span>"
    ]
  },
  {
    "objectID": "06-where-to-work.html#storage-size-restrictions-and-best-practices",
    "href": "06-where-to-work.html#storage-size-restrictions-and-best-practices",
    "title": "8  6 Where to Do Your Work",
    "section": "Storage Size Restrictions and Best Practices",
    "text": "Storage Size Restrictions and Best Practices\nStorage size varies by project, but is capped at a predetermined amount. Additional storage costs may vary depending on the resource requirements.\nBest Practices: - To save storage space, avoid saving copies of raw data tables. Instead, write code to access data. For detailed instructions on how to access data in structed data storage, please see the ADRF’s Redshift Querying Guide - Organize folders in a way that makes sense for your particular project. For example, you might have folders for a particular analysis or sub-projects. Dates on file names can be helpful for version control. - Keep tabs on how much storage you are using compared to the allocated amount of storage.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>6 Where to Do Your Work</span>"
    ]
  },
  {
    "objectID": "07-collaborate.html",
    "href": "07-collaborate.html",
    "title": "9  7 How to Work Collaboratively in the ADRF",
    "section": "",
    "text": "Topics",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>7 How to Work Collaboratively in the ADRF</span>"
    ]
  },
  {
    "objectID": "07-collaborate.html#topics",
    "href": "07-collaborate.html#topics",
    "title": "9  7 How to Work Collaboratively in the ADRF",
    "section": "",
    "text": "Shared Folders\nSharing Restrictions",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>7 How to Work Collaboratively in the ADRF</span>"
    ]
  },
  {
    "objectID": "07-collaborate.html#shared-folders",
    "href": "07-collaborate.html#shared-folders",
    "title": "9  7 How to Work Collaboratively in the ADRF",
    "section": "Shared Folders",
    "text": "Shared Folders\nShared folders within a project are a great way to share information with other members on a team project. Remember that when working with teams you may not share the ADRF screen (even project folders) with other members on video platforms or otherwise, whether or not your team members are working on the same project.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>7 How to Work Collaboratively in the ADRF</span>"
    ]
  },
  {
    "objectID": "07-collaborate.html#sharing-restrictions",
    "href": "07-collaborate.html#sharing-restrictions",
    "title": "9  7 How to Work Collaboratively in the ADRF",
    "section": "Sharing Restrictions",
    "text": "Sharing Restrictions\nAgain, remember that when working with teams you may not share the ADRF screen with other members on video platforms or otherwise, whether or not your team members are working on the same project.\nThe information contained in the ADRF is restricted to reside only in the ADRF for all purposes unless it passes Export Review. This means that it cannot be shared or potentially shared with any unauthorized parties. Do not write down any numbers or figures or tables corresponding to data in the ADRF. Copying and pasting is restricted, but manually circumventing this is also not permitted by your data agreements.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>7 How to Work Collaboratively in the ADRF</span>"
    ]
  },
  {
    "objectID": "08-export.html",
    "href": "08-export.html",
    "title": "10  8 How to Export Output from the ADRF",
    "section": "",
    "text": "Topics\nTo provide ADRF users with the ability to draw from sensitive data, results that are exported from the ADRF must meet rigorous standards meant to protect privacy and confidentiality. To ensure that those standards are met, the ADRF Export Review team reviews each request to ensure that it follows formal guidelines that are set by the respective agency providing the data in partnership with the Coleridge Initiative. Prior to moving data into the ADRF from the agency, the Export Review team suggests default guidelines to implement, based on standard statistical approaches in the U.S. government 1,2 as well as international standards 3, 4, and 5. The Data Steward from the agency supplying the data works with the team to amend these default rules in line with the agency’s requirements. If you are unsure about the review guidelines for the data you are using in the ADRF or if you have any questions relating to exports, please reach out to support@coleridgeinitiative.org before submitting an export request.\nTo learn more about limiting disclosure more generally, please refer to the Big Data and Social Science textbook or right-click here to view Coleridge’s Privacy and Confidentiality video series.\nNote: The Export Requester cannot be assigned as a reviewer of the same export.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>8 How to Export Output from the ADRF</span>"
    ]
  },
  {
    "objectID": "08-export.html#topics",
    "href": "08-export.html#topics",
    "title": "10  8 How to Export Output from the ADRF",
    "section": "",
    "text": "General Best Practices for a Successful Export\nTimelines for Export Process\nExport Review Process\nHow to Check Your Export Review Status\nPreparing Data for Export\nSubmitting an Export Request",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>8 How to Export Output from the ADRF</span>"
    ]
  },
  {
    "objectID": "08-export.html#general-best-practices-for-a-successful-export",
    "href": "08-export.html#general-best-practices-for-a-successful-export",
    "title": "10  8 How to Export Output from the ADRF",
    "section": "General Best Practices for a Successful Export",
    "text": "General Best Practices for a Successful Export\nNote: Currently, the review process is highly manual: Reviewers will read your code and view your output files, which may be time-consuming.\n\nEach additional release adds disclosure risk and therefore limits subsequent releases; we ask that users limit the number of files they request to export to just the outputs necessary to produce a particular report or paper. If you are requesting an export of more than 10 files, there may be an additional charge.\nThe reviewers may ask you to make changes to your code or output to meet the requirements of guidelines that have been given by the providers of the data in the ADRF. Thus, we strongly encourage you to produce all output files—tables with rounded numbers, graphs with titles, and so forth—through code, rather than manually.\nWe ask that you only request review of final versions of output files, rather than in-progress versions. Any file containing intermediate output will be rejected.\nEvery code file should have a header describing the contents of the file, including a summary of the data manipulation that takes place in the file (e.g., regression, table or figure creation, etc.).\nDocumenting code by using comments throughout is helpful for disclosure reviews. The better the documentation, the faster the turnaround of export requests. If data files are aggregated, please provide documentation on the level of aggregation and for where in the code the aggregation takes place.\nTo help reviewers, who may not have seen your code before, we ask that users create meaningful variable names. For instance, if you are calculating outflows, it is better to name the variable “outflows” than to name it “var1.”",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>8 How to Export Output from the ADRF</span>"
    ]
  },
  {
    "objectID": "08-export.html#timelines-for-export-process",
    "href": "08-export.html#timelines-for-export-process",
    "title": "10  8 How to Export Output from the ADRF",
    "section": "Timelines for Export Process",
    "text": "Timelines for Export Process\n\nColeridge reviewers have five business days to complete an export from the day you submit an export request. However, timelines may differ depending on your agency, so please refer to your specific agency’s guidelines.\nThe review process can be delayed if the reviewer needs additional information or if the reviewer needs you to make changes to your code or output to meet the ADRF nondisclosure requirements.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>8 How to Export Output from the ADRF</span>"
    ]
  },
  {
    "objectID": "08-export.html#export-review-process",
    "href": "08-export.html#export-review-process",
    "title": "10  8 How to Export Output from the ADRF",
    "section": "Export Review Process",
    "text": "Export Review Process\nThe ADRF Export Review process typically involves two main stages:\n\nPrimary Review: This is an initial, cursory review of your documentation and exports to ensure they do not include micro-data. A primary review can take up to 5 business days, so please plan accordingly when submitting your materials. In cases where the reviewer has questions or requires additional information, the primary review may extend beyond 5 business days.\nSecondary Review: This is a comprehensive review conducted by an approved Data Steward who has content knowledge for the data permissioned to your workspace. If your submission pertains to multiple data assets, it will require approval by each Data Steward before the material can be exported from the ADRF. Please plan accordingly.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>8 How to Export Output from the ADRF</span>"
    ]
  },
  {
    "objectID": "08-export.html#how-to-check-your-export-review-status",
    "href": "08-export.html#how-to-check-your-export-review-status",
    "title": "10  8 How to Export Output from the ADRF",
    "section": "How to Check Your Export Review Status:",
    "text": "How to Check Your Export Review Status:\nIf you’ve submitted an export request, you can easily check the status of your submission by following these steps:\n\nLog into the ADRF.\nOpen the ADRF Export module.\n\n\nReview status descriptions\nTo help you better understand the different stages of the Export Review process, here are the status descriptions you may encounter: 1. Awaiting Reviewer: Your export is currently under primary review. If any issues arise during the primary review, your reviewer will notify you. Upon completion of the primary review, the secondary reviewer(s) will be notified. 2. Awaiting Secondary Review: Your export is currently under secondary review. If your submission pertains to multiple data assets, it will require a review by each Data Steward before being approved.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>8 How to Export Output from the ADRF</span>"
    ]
  },
  {
    "objectID": "08-export.html#preparing-data-for-export",
    "href": "08-export.html#preparing-data-for-export",
    "title": "10  8 How to Export Output from the ADRF",
    "section": "Preparing Data for Export",
    "text": "Preparing Data for Export\nEach agency has specific disclosure review guidelines, especially with respect to the minimum allowable cell sizes for tables. Refer to these guidelines when preparing export requests. If you are unsure of what guidelines are in place for the dataset with which you are working in the ADRF, please reach out to support@coleridgeinitiative.org\n\nTables\n\nCell Sizes:\n\nFor individual-level data, please report the number of observations from each cell. For individual-level data, the default rule is to suppress cells with fewer than 10 observations, unless otherwise directed by the guidelines of the agency that provided the data.\nIf your table includes row or column totals or is dependent on a preceding or subsequent table, reviewers will need to take into account complementary disclosure risks—that is, whether the tables’ totals, or the separate tables when read together, might disclose information about individuals in the data in a way that a single, simpler table would not. Reviewers will work with you by offering guidance on implementing any necessary complementary suppression techniques.\n\nWeighted Data: If weighted results are to be exported, you must report both weighted and unweighted counts.\nRatios: If ratios are reported, please report the number of valid cases for both the numerator and the denominator (e.g., number of men in state X and number of women in state X, in addition to the ratio of women in state X).\nPercentiles: Do not report exact percentiles. Instead, for example, you may calculate a “fuzzy median,” by averaging the true 45th and 55th percentiles.\nPercentages: For any reported percentages or proportions, the underlying counts of individuals contributing to the numerators and denominators must be provided for each statistic in the desired export.\nMaxima and Minima:\n\nSuppress maximum and minimum values in general.\nYou may replace an exact maximum or minimum with a top-coded value.\n\n\n\n\nGraphs\n\nGraphs are representations of tables. Thus, for each graph (which may have, e.g., a jpg, pdf, png, or tif extension), provide the source data of the underlying table of the graph following the guidelines for tables above.\nBecause graphs and other figures take the most time to review, the number of generated graphs should be as low as possible. Please consider the possibility that you could export the underlying table instead, and generate the graph in another package.\nIf a graph is produced from aggregated data or from tables that have been disclosure-proofed following the guidelines above (e.g., bar charts of magnitudes), provide the underlying tables.\nIf a graph is produced directly from unit-record data but aggregated in the visualization (e.g., frequency histograms), provide the underlying tables.\nIf a graph is produced directly from unit-record data and displays unit-record values (e.g., scatterplots, plots of residuals), the graph can be released only after you ensure that individuals cannot be re-identified and that values can only be estimated with a high level of uncertainty. Further processing to meet this requirement can include, but is not restricted to, cutting off the tails of a distribution, removing outliers, jittering the actual values, and removing or modifying axis values.\nIf a graph is produced from the results of modeling or derivation and uses the unit-record data (e.g., regression curves), the graph can be released only if the values cannot be used to find original data values.\n\nGraphs of this type are generally automatically cleared.\nFor precision/recall graphs, you will need to report the sample size used to generate your model(s).\n\n\n\n\nModel Output\nOutput from regression or machine-learning models generally does not pose a risk of disclosing personally identifiable information, as long as the models are not based on small samples. Provide the counts for each variable that produces the model output. If categorical variables are used then provide the counts for each category.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>8 How to Export Output from the ADRF</span>"
    ]
  },
  {
    "objectID": "08-export.html#submitting-an-export-request",
    "href": "08-export.html#submitting-an-export-request",
    "title": "10  8 How to Export Output from the ADRF",
    "section": "Submitting an Export Request",
    "text": "Submitting an Export Request\nTo request an export be reviewed, please follow the instructions below or you can watch an instructional video by right-clicking this link.\n\nLog into the ADRF (http://adrf.okta.com).\nInput your login credentials.\nVerify yourself with Okta (download Okta Verify on your smartphone or other device).\nChoose your project as seen in the photo below. For the purpose of this document, you are seeing the Coleridge Initiative Associate Access project. \nSelect Desktop and login with the same credentials you had done previously.\nUpon entering the ADRF, a Google Chrome page will appear as shown in the photo below (the Getting Started page). On this page, click on the Export Request tile. Or, from the ADRF desktop, open Google Chrome and navigate to export.adrf.net. (Note: export.adrf.net is an address that will only work within the ADRF desktop). \nClick My Requests, or the top (person-shaped) icon, at the left side of the window as shown in the screenshot below. \nClick New Item as shown below \n\n\nYou will be asked to select the project to which your export relates. If you do not see the correct project listed in the dropdown list, please reach out to our support team at support@coleridgeinitiative.org.\n\n\nAfter selecting a project, click Continue. \nRead through the entire page that loads. This page, titled “Create Export Request,” will ask for you to comment on all supporting code files to explain the commands used to generate the files in the export request. The Export Review team will reject all requests containing intermediate output. The Export Review team will typically release export requests within five business days. However, if the team has any clarifying questions, this could result in a longer review process. You need to document your output files in the text box provided. See the example below: \nWhen you have read through and followed the page instructions, and are ready to proceed:\n\n\nMove the slider at the bottom of the page to indicate that you have followed the page’s guidelines.\nAt the bottom of the page, upload each of the files that you have prepared.\nClick Submit Request… to create the export request. \n\n\nYou can click My Requests at the left side of the window to view your current and previous export requests.\n\nNote: To learn more about exporting results, you can watch an instructional video by right-clicking this link.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>8 How to Export Output from the ADRF</span>"
    ]
  },
  {
    "objectID": "08-export.html#footnotes",
    "href": "08-export.html#footnotes",
    "title": "10  8 How to Export Output from the ADRF",
    "section": "",
    "text": "Confidential Information Protection and Statistical Efficiency Act of 2002. (Washington, DC: U.S. GPO, 2002).↩︎\nFederal Committee on Statistical Methodology. “Report on Statistical Disclosure Limitation Methodology,” 22 (Second Version, 2005). https://nces.ed.gov/fcsm/pdf/spwp22.pdf.↩︎\n“How to Use Microdata Properly: Self-Study Material for the Users of Eurostat Microdata Sets.” (2018). https://ec.europa.eu/eurostat/web/microdata/overview/self-study-material-for-microdata-users.↩︎\nResearch Data Centre of the German Federal Employment Agency at the Institute for Employment Research. “Remote Data Access and On-Site Use at the FDZ of the BA at the IAB.” (2020, December 8). http://doku.iab.de/fdz/access/Vorgaben_DAFE_EN.PDF.↩︎\nWelpton, Richard. Handbook on Statistical Disclosure Control for Outputs. (figshare, 2019). https://doi.org/10.6084/m9.figshare.9958520.v1.↩︎",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>8 How to Export Output from the ADRF</span>"
    ]
  },
  {
    "objectID": "09-dos-and-donts.html",
    "href": "09-dos-and-donts.html",
    "title": "11  9 Do’s and Don’ts for Discussing Data Hosted in the ADRF",
    "section": "",
    "text": "Exact Numbers\nYou must protect the confidential data that is hosted inside the ADRF in communicating with your teammates. The general rule is that you should never take any exact number out of the ADRF. This means you should never write down or share any number by text, screenshot, or share an image even with a team-mate. The rules have become more complicated now that everything is online, because even though your teammates are “safe people”, and Zoom conversations are password protected and encrypted, we’d rather err on the side of caution when sharing information over Zoom.\nTo ensure safe outputs, the Coleridge Initiative works with an agency’s Data Steward to develop rigorous export review requirements catered to the specific needs of the partner agency. While you should make sure to acquaint yourself with the specific export rules associated with the confidential data you have been approved to access, cheat sheet provided below summarizes some of the rules that apply to discussing data before it has been exported from the ADRF and passed the ADRF team’s disclosure review.\nIf you are unsure about a specific situation, please ask reach out to the Coleridge Support Team at support@coleridgeinitiative.org. ## Topics - Comparing Values - Exact Numbers - Percentages and Proportions\nDo not describe a statistic in exact numbers. If you would like to communicate these values while not in person, you can have a private discussion via the projects drive inside the ADRF.\nExample: If an average within a specific group was 5,000, you would need to convey this average on the projects drive.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>9 Do's and Don'ts for Discussing Data Hosted in the ADRF</span>"
    ]
  },
  {
    "objectID": "09-dos-and-donts.html#comparing-values",
    "href": "09-dos-and-donts.html#comparing-values",
    "title": "11  9 Do’s and Don’ts for Discussing Data Hosted in the ADRF",
    "section": "Comparing Values",
    "text": "Comparing Values\nWhen comparing values, you are permitted to say that one value is more than, less than, or about the same as another. However, you cannot refer to the exact difference between the two numbers.\nIn practice, you can use pluses and minuses to convey differences between values for data that has not been exported from the ADRF.\nExample: “The mean for Group A was roughly the same as the mean for Group B, but these values were both greater than that of Group C.”",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>9 Do's and Don'ts for Discussing Data Hosted in the ADRF</span>"
    ]
  },
  {
    "objectID": "09-dos-and-donts.html#percentages-and-proportions",
    "href": "09-dos-and-donts.html#percentages-and-proportions",
    "title": "11  9 Do’s and Don’ts for Discussing Data Hosted in the ADRF",
    "section": "Percentages and Proportions",
    "text": "Percentages and Proportions\nPercentages and proportions also cannot be directly mentioned. Instead, you can refer to the percentage/proportion within 25%.\nExample: If a proportion was 30%, you could say “The proportion is about 25%” or “The proportion is between 25% and 50%.”",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>9 Do's and Don'ts for Discussing Data Hosted in the ADRF</span>"
    ]
  },
  {
    "objectID": "10-packages.html",
    "href": "10-packages.html",
    "title": "12  10 Adding Additional Packages in R/Python",
    "section": "",
    "text": "Topics\nThe ADRF has an internal package repository, so users can install packages for R and Python themselves.\nThe repositories that are currently mirrored in the ADRF are CRAN for R packages and PyPi.org for Python. There is currently no access to packages hosted on Github or other mirrors.\nNote: If you are working in a shared workspace for a project, each user in the project must install the packages, there is no shared package installation for projects.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>10 Adding Additional Packages in R/Python</span>"
    ]
  },
  {
    "objectID": "10-packages.html#topics",
    "href": "10-packages.html#topics",
    "title": "12  10 Adding Additional Packages in R/Python",
    "section": "",
    "text": "Add additional R packages\nAdd additional Python packages",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>10 Adding Additional Packages in R/Python</span>"
    ]
  },
  {
    "objectID": "10-packages.html#add-additional-r-packages",
    "href": "10-packages.html#add-additional-r-packages",
    "title": "12  10 Adding Additional Packages in R/Python",
    "section": "Add additional R packages",
    "text": "Add additional R packages\nTo install R packages, simply use the code below and the package will be installed from the repository. You will not have to re-install the package again, and to use the package load it with the library() function. For example:\ninstall.packages(\"packagename\")\n** Example**: Installing tidyverse\n\n\n\nInstall tidyverse\n\n\nTo install a specific package version you can specify:\ninstall.packages(\"remotes\")\n\nremotes::install_version(\"tidyverse\", \"1.3.2\")\nNote: We recommend starting R using Rstudio for best results, instead of double clicking on a R or Rmarkdown script.",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>10 Adding Additional Packages in R/Python</span>"
    ]
  },
  {
    "objectID": "10-packages.html#add-additional-python-packages",
    "href": "10-packages.html#add-additional-python-packages",
    "title": "12  10 Adding Additional Packages in R/Python",
    "section": "Add additional Python packages",
    "text": "Add additional Python packages\nSimilar to R packages, Python packages may be installed using the Package Installer for Python (pip).\nNote: We recommend installing python packages from the command line. If you start Jupyter lab, and choose the Terminal tab:\n\n\n\nIf you start Juypter Lab, choose the Terminal tab\n\n\nThen install your package using pip, for example, to install the pandas package:\n\n\n\nExample: pandas package installation\n\n\nThen you may use the package within your Jupyter notebook as usual.\nTo install a specific package version type:\npip install pandas==1.2.3",
    "crumbs": [
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>10 Adding Additional Packages in R/Python</span>"
    ]
  },
  {
    "objectID": "11-querying-guide.html",
    "href": "11-querying-guide.html",
    "title": "13  11 Redshift Querying Guide",
    "section": "",
    "text": "Topics\nThis section provides an introduction to generating proficient Amazon Redshift queries. This is a generalized document meaning you will need to replace “schema_name” and “table_name” with the appropriate schema and table names used for your project.\nNote: All data is stored under schemas in the projects database.",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>11 Redshift Querying Guide</span>"
    ]
  },
  {
    "objectID": "11-querying-guide.html#topics",
    "href": "11-querying-guide.html#topics",
    "title": "13  11 Redshift Querying Guide",
    "section": "",
    "text": "Data Access\nUsing DBeaver to access a database\n\nCreating tables in a PR or TR schema in Dbeaver\n\nConnecting to a database through a statistical program\n\nConnecting to a database using SAS\nConnecting to a database using R\nConnecting to a database using Python\nConnecting to a database using Stata\n\nRedshift Query Guidelines for Researchers",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>11 Redshift Querying Guide</span>"
    ]
  },
  {
    "objectID": "11-querying-guide.html#data-access",
    "href": "11-querying-guide.html#data-access",
    "title": "13  11 Redshift Querying Guide",
    "section": "Data access",
    "text": "Data access\nIf you are approved to access data that are stored in a database, the data are housed in Redshift. To access those data, you will have to log in to Redshift within your workspace.\nYou need to replace the “user.name.project” with your project workspace username. The project workspace username is your user folder name in the U:/ drive:\n\n\n\nImage of Project-Based User Name\n\n\nNote: You will need to enter your specific user name when logging into Redshift. The password needed to access Redshift is the second password entered when logging into the ADRF as shown in the screen below:",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>11 Redshift Querying Guide</span>"
    ]
  },
  {
    "objectID": "11-querying-guide.html#using-dbeaver-to-access-a-database",
    "href": "11-querying-guide.html#using-dbeaver-to-access-a-database",
    "title": "13  11 Redshift Querying Guide",
    "section": "Using DBeaver to access a database",
    "text": "Using DBeaver to access a database\nTo establish a connection to Redshift in DBeaver, first open DBeaver by clicking on the DBeaver icon located on the ADRF desktop and then double click on the server you wish to connect to. Note: All data is stored under schemas in the projects database.\nIn the example below, we will connect to Redshift11_projects. After double clicking on Reshift11_projects, a window will appear asking for your Username and Password. - In Username, enter “adrf\\” followed by your project workspace username - In Password, enter the password associated with your project workspace username \nAfter completing the Username and Password fields, click OK. You will now have access to your data stored on the Redshift11_projects server.\nNote: Please make sure to enter “adrf\\” before your project workspace username in the Username field. If you do not enter “adrf\", or accidently include a”/” instead of a “\\”, you will not be able to connect to Redshift. If you are having trouble connecting, an incorrect entry in Username is most likely the culprit.\n\nCreating tables in a PR or TR schema in Dbeaver\nWhen users create tables in their PR (Research Project) or TR (Training Project) schema, the table is initially permissioned to the user only. This is analogous to creating a document or file in your U drive: Only you have access to the newly created table.\nIf you want to allow all individuals in your project workspace to access the table in the PR/TR schema, you will need to grant permission to the table to the rest of the users who have access to the PR or TR schema.\nYou can do this by running the following code: GRANT SELECT, UPDATE, DELETE, INSERT ON TABLE schema_name.table_name TO group db_xxxxxx_rw;\nNote: Note: In the above code example replace schma_name with the pr_ or tr_ schema assigned to your workspace and replace table_name with the name of the table on which you want to grant access. Also, in the group name db_xxxxxx_rw, replace xxxxxx with your project code. This is the last 6 characters in your project based user name. This will start with either a T or a P.\nIf you want to allow only a single user on your project to access the table, you will need to grant permission to that user. You can do this by running the following code:\nGRANT SELECT, UPDATE, DELETE, INSERT ON TABLE schema_name.table_name to \"IAM:first_name.last_name.project_code\";\nNote: In the above code example replace schma_name with the pr_ or tr_ schema assigned to your workspace and replace table_name with the name of the table on which you want to grant access. Also, in \"IAM:first_name.last_name.project_code\" update first_name.last_name.project_code with the user name to whom you want to grant access to.\nIf you have any questions, please reach out to us at support@coleridgeinitiative.org",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>11 Redshift Querying Guide</span>"
    ]
  },
  {
    "objectID": "11-querying-guide.html#connecting-to-a-database-through-a-statistical-program",
    "href": "11-querying-guide.html#connecting-to-a-database-through-a-statistical-program",
    "title": "13  11 Redshift Querying Guide",
    "section": "Connecting to a database through a statistical program",
    "text": "Connecting to a database through a statistical program\nWhen connecting to the database using an ODBC connection, you need to use one of the following DSNs:\n\nRedshift01_projects_DSN\nRedshift11_projects_DSN\n\nIn the code examples below, the default DSN is Redshift01_projects_DSN.\nTopics: - Connecting to a database using SAS - Connecting to a database using R - Connecting to a database using Python - Connecting to a database using Stata\n\nConnecting to a database using SAS\nUse the following code to connect to a databse using SAS:\nproc sql;\nconnect to odbc as my con\n(datasrc=Redshift01_projects_DSN user=adrf\\user.name.project password=password);\nselect * from connection to mycon\n(select * form projects.schema.table);\ndisconnect from mycon;\nquit;\n\n\nConnecting to a database using R\n\nRecommended method for connecting to a database using R\nUsing Renviron file to connect to a database using R\nBest practices for loading large amounts of data in R\n\n\nRecommended method for connecting to a database using R\nNote: To use this method, you may need to install the packages RJDBC and rstudioapi first.\nlibrary(RJDBC)\n\n# Create username\ndbusr=paste(\"ADRF\\\\\", Sys.getenv(\"USERNAME\"), sep= '')                                                                                \n\n# Database URL\nurl &lt;- paste0(\"jdbc:redshift:iam://adrf-redshift01.cdy8ch2udktk.us-gov-west-1.redshift.amazonaws.com:5439/projects;\",\n              \"loginToRp=urn:amazon:webservices:govcloud;\",\n              \"ssl=true;\",\n              \"AutoCreate=true;\",\n              \"idp_host=adfs.adrf.net;\",\n              \"idp_port=443;\",\n              \"ssl_insecure=true;\",\n              \"plugin_name=com.amazon.redshift.plugin.AdfsCredentialsProvider\")\n\n# Redshift JDBC Driver Setting\ndriver &lt;- JDBC(\"com.amazon.redshift.jdbc42.Driver\",\n               classPath = \"C:\\\\drivers\\\\redshift_withsdk\\\\redshift-jdbc42-2.1.0.12\\\\redshift-jdbc42-2.1.0.12.jar\",\n               identifier.quote=\"`\")\ncon &lt;- dbConnect(driver, url, dbusr, rstudioapi::askForPassword())\n\n\nUsing Renviron file to connect to a database using R\nlibrary(RJDBC)\ndbusr=Sys.getenv(\"DBUSER\")                                                                    dbpswd=Sys.getenv(\"DBPASSWD\")\n\n# Database URL\nurl &lt;- paste0(\"jdbc:redshift:iam://adrf-redshift01.cdy8ch2udktk.us-gov-west-1.redshift.amazonaws.com:5439/projects;\",\n\"loginToRp=urn:amazon:webservices:govcloud;\",\n\"ssl=true;\",\n\"AutoCreate=true;\",\n\"idp_host=adfs.adrf.net;\",\n\"idp_port=443;\",\n\"ssl_insecure=true;\",\n\"plugin_name=com.amazon.redshift.plugin.AdfsCredentialsProvider\")\n\n# Redshift JDBC Driver Setting\ndriver &lt;- JDBC(\"com.amazon.redshift.jdbc42.Driver\",\nclassPath = \"C:\\\\drivers\\\\redshift_withsdk\\\\redshift-jdbc42-2.1.0.12\\\\redshift-jdbc42-2.1.0.12.jar\",\nidentifier.quote=\"`\")\nconn &lt;- dbConnect(driver, url, dbusr, dbpswd)\nNote: For the above code to work, please create a file name .Renviron in your user folder (user folder is something like i.e. u:\\John.doe.p00002) And .Renviron file should contain the following:\nDBUSER='adrf\\John.doe.p00002'\nDBPASSWD='xxxxxxxxxxxx'\n_ Note replace user id and password with your project workspace specific user id and password.\nThis will ensure you don’t have your id and password in R code and then you can easily share your R code with others without sharing your ID and password._\n\n\nBest practices for loading large amounts of data in R\n\nSQL Basics with R Programming\nTo ensure R can efficiently manage large amounts of data, please add the following lines of code to your R script before any packages are loaded:\noptions(java.parameters = c(\"-XX:+UseConcMarkSweepGC\", \"-Xmx8192m\"))\ngc()\n\n\nBest practices for writing tables to Redshift\nWhen writing an R data frame to Redshift use the following code as an example:\n# Note: replace the table_name with the name of the data frame you wish to write to Redshift\n\nDBI::dbWriteTable(conn = conn, #name of the connection \nname = \"schema_name.table_name\", #name of table to save df to \nvalue = df_name, #name of df to write to Redshift \noverwrite = TRUE) #if you want to overwrite a current table, otherwise FALSE\n\nqry &lt;- \"GRANT SELECT ON TABLE schema.table_name TO group &lt;group_name&gt;;\"\ndbSendUpdate(conn,qry)\n\n\n\n\nConnecting to a database using Python\nimport pyodbc\nimport pandas as pd\ncnxn = pyodbc.connect('DSN=Redshift01_projects_DSN; UID=adrf\\user.name.project; PWD=password')\ndf = pd.read_sql(\"SELECT * FROM projects.schema_name.table_name\", cnxn)\n\n\nConnecting to a database using Stata\nodbc load, exec(\"select * from PATH_TO_TABLE\") clear dsn(\"Redshift11_projects_DSN\") user(\"adrf\\user.name.project\") password(\"password\")",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>11 Redshift Querying Guide</span>"
    ]
  },
  {
    "objectID": "11-querying-guide.html#redshift-query-guidelines-for-researchers",
    "href": "11-querying-guide.html#redshift-query-guidelines-for-researchers",
    "title": "13  11 Redshift Querying Guide",
    "section": "Redshift Query Guidelines for Researchers",
    "text": "Redshift Query Guidelines for Researchers\nDeveloping your query. Here’s an example workflow to follow when developing a query.\n\nStudy the column and table metadata, which is accessible via the table definition. Each table definition can be displayed by clicking on the [+] next the table name.\nTo get a feel for a table’s values, SELECT * from the tables you’re working with and LIMIT your results (Keep the LIMIT applied as you refine your columns) or use (e.g., select * from [table name] LIMIT 1000)\nNarrow down the columns to the minimal set required to answer your question.\nApply any filters to those columns.\nIf you need to aggregate data, aggregate a small number of rows\nOnce you have a query returning the results you need, look for sections of the query to save as a Common Table Expression (CTE) to encapsulate that logic.\n\n\nQuery Tips and Best Practices\n\nTip 1: Use SELECT &lt;columns&gt; instead of SELECT *\nSpecify the columns in the SELECT clause instead of using SELECT *. The unnecessary columns place extra load on the database, which slows down not just the single Amazon Redshift, but the whole system.\nInefficient\nSELECT * FROM projects.schema_name.table_name\nThis query fetches all the data stored in the table you choose which might not be required for a particular scenario.\nEfficient\nSELECT col_A, col_B, col_C FROM projects.schema_name.table_name\n\n\nTip 2: Always fetch limited data and target accurate results\nLesser the data retrieved, the faster the query will run. Rather than applying too many filters on the client-side, filter the data as much as possible at the server. This limits the data being sent on the wire and you’ll be able to see the results much faster. In Amazon Redshift use LIMIT (###) qualifier at the end of the query to limit records.\nSELECT col_A, col_B, col_C FROM projects.schema_name.table_name WHERE [apply some filter] LIMIT 1000\n\n\nTip 3: Use wildcard characters wisely\nWildcard characters can be either used as a prefix or a suffix. Using leading wildcard (%) in combination with an ending wildcard will search all records for a match anywhere within the selected field.\nInefficient\nSelect col_A, col_B, col_C from projects.schema_name.table_name where col_A like '%BRO%'\nThis query will pull the expected results of Brown Sugar, Brownie, Brown Rice and so on. However, it will also pull unexpected results, such as Country Brown, Lamb with Broth, Cream of Broccoli.\nEfficient\nSelect col_A, col_B, col_C from projects.schema_name.table_name where col_B like 'BRO%'.\nThis query will pull only the expected results of Brownie, Brown Rice, Brown Sugar and so on.\n\n\nTip 4: Does My record exist?\nNormally, developers use EXISTS() or COUNT() queries for matching a record entry. However, EXISTS() is more efficient as it will exit as soon as finding a matching record; whereas, COUNT() will scan the entire table even if the record is found in the first row.\nEfficient\nselect col_A from projects.schema_name.table_name A where exists (select 1 from projects.schema_name.table_name B where A.col_A = B.col_A ) order by col_A;\n\n\nTip 5: Avoidcorrelated subqueries\nA correlated subquery depends on the parent or outer query. Since it executes row by row, it decreases the overall speed of the process.\nInefficient\nSELECT col_A, col_B, (SELECT col_C FROM projects.schema_name.table_name_a WHERE col_C = c.rma LIMIT 1) AS new_name FROM projects.schema_name.table_name_b\nHere, the problem is that the inner query is run for each row returned by the outer query. Going over the table_name_b table again and again for every row processed by the outer query creates process overhead. Instead, for Amazon Redshift query optimization, use JOIN to solve such problems.\nEfficient\nSELECT col_A, col_B, col_C FROM projects.schema_name.table_name c LEFT JOIN projects.schema_name.table_name co ON c.col_A = co.col_B\n\n\nTip 6: Avoid using Amazon Redshift function in the where condition\nOften developers use functions or methods with their Amazon Redshift queries.\nInefficient\nSELECT col_A, col_B, col_C FROM projects.schema_name.table_name WHERE RIGHT(birth_date,4) = '1965' and LEFT(birth_date,2) = '07'\nNote that even if birth_date has an index, the above query changes the WHERE clause in such a way that this index cannot be used anymore.\nEfficient\nSELECT col_A, col_B, col_C FROM projects.schema_name.table_name WHERE birth_date between '711965' and '7311965'\n\n\nTip 7: Use WHERE instead of HAVING\nHAVING clause filters the rows after all the rows are selected. It is just like a filter. Do not use the HAVING clause for any other purposes. It is useful when performing group bys and aggregations.\n\n\nTip 8: Use temp tables when merging large data sets\nCreating local temp tables will limit the number of records in large table joins and merges. Instead of performing large table joins, one can break out the analysis by performing the analysis in two steps: 1. Create a temp table with limiting criteria to create a smaller / filtered result set. 2. Join the temp table to the second large table to limit the number of records being fetched and to speed up the query.\nThis is especially useful when there are no indexes on the join columns.\nInefficient\nSELECT col_A, col_B, sum(col_C) total FROM projects.schema_name.table_name pd INNER JOIN projects.schema_name.table_name st ON pd.col_A=st.col_B WHERE pd.col_C like 'DOG%' GROUP BY pd.col_A, pd.col_B, pd.col_C\nNote that even if joining column col_A has an index, the col_B column does not. In addition, because the size of some tables can be large, one should limit the size of the join table by first building a smaller filtered #temp table then performing the table joins.\nEfficient\nSET search_path = schema_name;\nNote: This statement sets the default schema/database to projects.schema_name\nStep 1:\nCREATE TEMP TABLE temp_table (col_A varchar(14), col_B varchar(178), col_C varchar(4));\nStep 2:\nINSERT INTO temp_table SELECT col_A, col_B, col_C\nFROM projects.schema_name.table_name WHERE col_B like 'CAT%';\nStep 3:\nSELECT pd.col_A, pd.col_B, pd.col_C, sum(col_C) as total FROM temp_table pd INNER JOIN projects.schema_name.table_name st ON pd.col_A=st.col_B GROUP BY pd.col_A, pd.col_B, pd.col_C;\n\nDROP TABLE temp_table;\nNote always drop the temp table after the analysis is complete to release data from physical memory.\n\n\n\nOther Pointers for best database performance\nSELECT columns, not stars. Specify the columns you’d like to include in the results (though it’s fine to use * when first exploring tables — just remember to LIMIT your results).\nAvoid using SELECT DISTINCT. The `SELECT DISTINCT1 command in Amazon Redshift used for fetching unique results and remove duplicate rows in the relation. To achieve this task, it basically groups together related rows and then removes them. GROUP BY operation is a costly operation. To fetch distinct rows and remove duplicate rows, use more attributes in the SELECT operation.\nInner joins vs WHERE clause. Use inner join for merging two or more tables rather than using the WHERE clause. The WHERE clause creates the CROSS join/ CARTESIAN product for merging tables. The CARTESIAN product of two tables takes a lot of time.\nIN versus EXISTS. The IN operator is costlier than EXISTS in terms of scans especially when the result of the subquery is a large dataset. We should try to use EXISTS rather than using IN for fetching results with a subquery.\nAvoid\nSELECT col_A , col_B, col_C\n\nFROM projects.schema_name.table_name\n\nWHERE col_A IN\n\n(SELECT col_B FROM projects.schema_name.table_name WHERE col_B = 'DOG')\nPrefer\nSELECT col_A , col_B, col_C\n\nFROM projects.schema_name.table_name\n\nWHERE EXISTS\n\n(SELECT col_A FROM projects.schema_name.table_name b WHERE\n\na.col_A = b.col_B and b.col_B = 'DOG')\nQuery optimizers can change the order of the following list, but this general lifecycle of a Amazon Redshift query is good to keep in mind when writing Amazon Redshift.\n\nFROM (and JOIN) get(s) the tables referenced in the query.\nWHERE filters data.\nGROUP BY aggregates data.\nHAVING filters out aggregated data that doesn’t meet the criteria.\nSELECT grabs the columns (then deduplicates rows if DISTINCT is invoked).\nUNION merges the selected data into a result set.\nORDER BY sorts the results.\n\n\n\nAmazon Redshift best practices for FROM\nJoin tables using the ON keyword. Although it’s possible to “join” two tables using a WHERE clause, use an explicit JOIN. The JOIN + ON syntax distinguishes joins from WHERE clauses intended to filter the results.\nSET search_path = schema_name; -– this statement sets the default schema/database to projects.schema_name\n\nSELECT A.col_A , B.col_B, B.col_C\n\nFROM projects.schema_name.table_name as A\n\nJOIN projects.schema_name.table_name B ON A.col_A = B.col_B\nAlias multiple tables. When querying multiple tables, use aliases, and employ those aliases in your select statement, so the database (and your reader) doesn’t need to parse which column belongs to which table.\nAvoid\nSET search_path = schema_name; -– this statement sets the default schema/database to projects.schema_name\n\nSELECT col_A , col_B, col_C\n\nFROM dbo.table_name as A\n\nLEFT JOIN dbo.table_name as B ON A.col_A = B.col_B\nPrefer\nSET search_path = schema_name;– this statement sets the default schema/database to projects.schema_name\n\nSELECT A.col_A , B.col_B, B.col_C\n\nFROM dbo.table_name as A\n\nLEFT JOIN dbo.table_name as B\n\nA.col_A = B.col_B\n\n\nAmazon Redshift best practices for WHERE\nFilter with WHERE before HAVING. Use a WHERE clause to filter superfluous rows, so you don’t have to compute those values in the first place. Only after removing irrelevant rows, and after aggregating those rows and grouping them, include a HAVING clause to filter out aggregates.\nAvoid functions on columns in WHERE clauses. Using a function on a column in a WHERE clause can really slow down your query, as the function prevents the database from using an index to speed up the query. Instead of using the index to skip to the relevant rows, the function on the column forces the database to run the function on each row of the table. The concatenation operator || is also a function, so don’t try to concat strings to filter multiple columns. Prefer multiple conditions instead:\nAvoid\nSELECT col_A, col_B, col_C FROM projects.schema_name.table_name\n\nWHERE concat(col_A, col_B) = 'REGULARCOFFEE'\nPrefer\nSELECT col_A, col_B, col_C FROM projects.schema_name.table_name\n\nWHERE col_A ='REGULAR' and col_B = 'COFFEE'\n\n\nAmazon Redshift best practices for GROUP BY\nOrder multiple groupings by descending cardinality. Where possible, GROUP BY columns in order of descending cardinality. That is, group by columns with more unique values first (like IDs or phone numbers) before grouping by columns with fewer distinct values (like state or gender).\n\n\nAmazon Redshift best practices for HAVING\nOnly use HAVING for filtering aggregates. Before HAVING, filter out values using a WHERE clause before aggregating and grouping those values.\nSELECT col_A, sum(col_B) as total_amt\n\nFROM projects.schema_name.table_name\n\nWHERE col_C = 1617 and col_A='key'\n\nGROUP BY col_A\n\nHAVING sum(col_D)&gt; 0\n\n\nAmazon Redshift best practices for UNION\nPrefer UNION ALL to UNION. If duplicates are not an issue, UNION ALL won’t discard them, and since UNION ALL isn’t tasked with removing duplicates, the query will be more efficient.\n\n\nAmazon Redshift best practices for ORDER BY\nAvoid sorting where possible, especially in subqueries. If you must sort, make sure your subqueries are not needlessly sorting data.\nAvoid\nSELECT col_A, col_B, col_C\n\nFROM projects.schema_name.table_name\n\nWHERE col_B IN\n\n(SELECT col_A FROM projects.schema_name.table_name\n\nWHERE col_C = 534905 ORDER BY col_B);\nPrefer\nSELECT col_A, col_B, col_C\n\nFROM projects.schema_name.table_name\n\nWHERE col_A IN\n\n(SELECT col_B FROM projects.schema_name.table_name\n\nWHERE col_C = 534905);\n\n\nTroubleshooting Queries\nThere are several metrics for calculating the cost of the query in terms of storage, time, CPU utilization. However, these metrics require DBA permissions to execute. Follow up with ADRF support to get additional assistance.\nUsing the SVL_QUERY_SUMMARY view: To analyze query summary information by stream, do the following:\nStep 1: select query, elapsed, substring from svl_qlog order by query desc limit 5;\nStep 2: select * from svl_query_summary where query = MyQueryID order by stm, seg, step;\nExecution Plan: Lastly, an execution plan is a detailed step-by-step processing plan used by the optimizer to fetch the rows. It can be enabled in the database using the following procedure:\n\nClick on SQL Editor in the menu bar.\nClick on Explain Execution Plan.\n\nIt helps to analyze the major phases in the execution of a query. We can also find out which part of the execution is taking more time and optimize that sub-part. The execution plan shows which tables were accessed, what index scans were performed for fetching the data. If joins are present it shows how these tables were merged. Further, we can see a more detailed analysis view of each sub-operation performed during query execution.",
    "crumbs": [
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>11 Redshift Querying Guide</span>"
    ]
  },
  {
    "objectID": "12-dashboards.html",
    "href": "12-dashboards.html",
    "title": "14  12 Accessing ADRF Dashboards",
    "section": "",
    "text": "Topics\nSome users will be approved to access an ADRF Dashboard. This section provides step-by-step instructions for accessing ADRF Dashboards.\nNote: If you are a first-time ADRF Users, please follow the instructions in the Onboarding Modules and Security Training to activate your ADRF account and complete your onboarding tasks.",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>12 Accessing ADRF Dashboards</span>"
    ]
  },
  {
    "objectID": "12-dashboards.html#topics",
    "href": "12-dashboards.html#topics",
    "title": "14  12 Accessing ADRF Dashboards",
    "section": "",
    "text": "Step 1: Setting your dashboard access password\nStep 2: Accessing the Dashboard",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>12 Accessing ADRF Dashboards</span>"
    ]
  },
  {
    "objectID": "12-dashboards.html#step-1-setting-your-dashboard-access-password",
    "href": "12-dashboards.html#step-1-setting-your-dashboard-access-password",
    "title": "14  12 Accessing ADRF Dashboards",
    "section": "Step 1: Setting your dashboard access password",
    "text": "Step 1: Setting your dashboard access password\nOnce you have completed the management portal onboarding tasks, you will next need to set your dashboard access password. This is separate from the first password you use to access the ADRF through Okta, and will instead be used to provide specific access to the dashboard. You should only need to do this the first time you access the dashboard, but you can always follow these instructions if you need to update or reset your dashboard access password in the future.\n\nIn the Management Portal, again navigate to the “Admin Tasks” page by clicking the link on the sidebar navigation menu:\n\n\n\n\nAdmin Tasks\n\n\n\nClick on the “Reset Password” button:\n\n\n\n\nClick on Reset Password\n\n\n\nThis will load the password reset window:\n\n\n\n\nThis will load the password reset window\n\n\n\nSelect the account associated with the dashboard by clicking on the checkbox on the right:\n\n\n\n\nSelect account\n\n\nImportant: Take note of the username associated with your dashboard (John.Doe.P00000 in this example). You will need to enter this username again in the next step. This is also the user name referenced in your onboarding email.\n\nEnter the desired password. The chosen password must adhere to the ADRF password policy:\n\n\n\n\nEnter new password\n\n\n\nClick the “Reset Password” button to proceed with the update. You will receive confirmation at the bottom of the window once the password has been successfully updated:\n\n\n\n\nReset password",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>12 Accessing ADRF Dashboards</span>"
    ]
  },
  {
    "objectID": "12-dashboards.html#step-2-accessing-the-dashboard",
    "href": "12-dashboards.html#step-2-accessing-the-dashboard",
    "title": "14  12 Accessing ADRF Dashboards",
    "section": "Step 2: Accessing the Dashboard",
    "text": "Step 2: Accessing the Dashboard\nOnce you have successfully reset your dashboard access password, you are ready to access the dashboard. To do so, navigate back to the main Okta portal (adrf.okta.com) and click on the tile associated with your dashboard. This tile will be unavailable until you complete the three ADRF onboarding tasks discussed in Onboarding Modules and Security Training:\n\n\n\nYour Dashboard\n\n\nClicking on this will bring up another window where you will be prompted to “Choose Your Application to Get Started.” Click on your Dashboard icon:\n\n\n\nChoose your application to get started\n\n\nNext, you will need to wait for your session to be prepared. Then, your session will load the secure browser window, which will then bring up the Posit Connect portal. The Posit Connect portal is used to host the Dashboard. This step may take several seconds while the browser loads and prepares the dashboard data.\nBefore accessing the dashboard, you will then be presented with one final request to log into the secure Connect environment.:\n\n\n\nLogin to the Secure Connect Environment\n\n\nHere, please enter:\n\nThe username you saw in the Password Reset step above (e.g., John.Doe.P00000)\nYour dashboard access password that you set in Step 2.\n\n\n\n\nEnter your credentials\n\n\nOnce you enter the appropriate information and click “Log In,” your dashboard should begin to load. This again may take a minute or two - if you run into any issues, please reach out to us at support@coleridgeinitiative.org.",
    "crumbs": [
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>12 Accessing ADRF Dashboards</span>"
    ]
  },
  {
    "objectID": "13-faq.html",
    "href": "13-faq.html",
    "title": "15  13 Frequently Asked Questions (FAQ)",
    "section": "",
    "text": "Topics",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>13 Frequently Asked Questions (FAQ)</span>"
    ]
  },
  {
    "objectID": "13-faq.html#topics",
    "href": "13-faq.html#topics",
    "title": "15  13 Frequently Asked Questions (FAQ)",
    "section": "",
    "text": "How do I set up my Multifactor Authentication\nCan I set up more than one form of Multifactor Authentication?\nHow can I reset my Okta password?\nHow can I reset my ADRF password?\nWhat if I do not remember my security questions or if I get locked out?\nI can log into the ADRF but my desktop and DS application just show blank pages.\nI saved a file in the C: drive or in the Desktop. When I logged back in, the file is no longer there. Can you restore it?\nHow do I open an ipynb notebook?\nHow can I ingest publicly available data into the ADRF?\nWhere can I access publicly available data from within the ADRF?\nWhere is my project or training related data stored?\nMy data is not in a relational format. Where can I find these files?\nWhat is the difference between the P:, U: and G: drives?\nI need to process a large amount of relational data. What is the destination location?",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>13 Frequently Asked Questions (FAQ)</span>"
    ]
  },
  {
    "objectID": "13-faq.html#how-do-i-set-up-my-multifactor-authentication",
    "href": "13-faq.html#how-do-i-set-up-my-multifactor-authentication",
    "title": "15  13 Frequently Asked Questions (FAQ)",
    "section": "How do I set up my Multifactor Authentication",
    "text": "How do I set up my Multifactor Authentication\nYou should be prompted to set up multifactor authentication when you create your account, the options are SMS, voice call, email and the Okta verify application.",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>13 Frequently Asked Questions (FAQ)</span>"
    ]
  },
  {
    "objectID": "13-faq.html#can-i-set-up-more-than-one-form-of-multifactor-authentication",
    "href": "13-faq.html#can-i-set-up-more-than-one-form-of-multifactor-authentication",
    "title": "15  13 Frequently Asked Questions (FAQ)",
    "section": "Can I set up more than one form of Multifactor Authentication?",
    "text": "Can I set up more than one form of Multifactor Authentication?\nThis is recommended. If you lose access to one form of MFA, you would still be able to gain access to your account using an alternative. To do so, please log on to https://adrf.okta.com and select your name on the top right and click settings. Here you can modify or set up your SMS, voice call, email or Okta multifactor authentication.",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>13 Frequently Asked Questions (FAQ)</span>"
    ]
  },
  {
    "objectID": "13-faq.html#how-can-i-reset-my-okta-password",
    "href": "13-faq.html#how-can-i-reset-my-okta-password",
    "title": "15  13 Frequently Asked Questions (FAQ)",
    "section": "How can I reset my Okta password?",
    "text": "How can I reset my Okta password?\nYou can use the “Need help signing in?” option on the sign on page (https://adrf.okta.com) which will send a link to your email to reset your password. You may have to verify your identify by answering security questions which you set up when creating your account.",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>13 Frequently Asked Questions (FAQ)</span>"
    ]
  },
  {
    "objectID": "13-faq.html#how-can-i-reset-my-adrf-password",
    "href": "13-faq.html#how-can-i-reset-my-adrf-password",
    "title": "15  13 Frequently Asked Questions (FAQ)",
    "section": "How can I reset my ADRF password?",
    "text": "How can I reset my ADRF password?\nYou can reset your ADRF project password by following these steps:\n\nClick on the ADRF Management Portal Okta Tile:\n\n\n\n\nADRF Management Portal Icon\n\n\n\nThen click on Admin Tasks on the left hand side of the screen:\n\n\n\n\nAdmin Tasks\n\n\n\nThen click on RESET PASSWORD:\n\n\n\n\nReset Password\n\n\nYou’ll see a screen where you can choose the project(s) for which you want to update the password.",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>13 Frequently Asked Questions (FAQ)</span>"
    ]
  },
  {
    "objectID": "13-faq.html#what-if-i-do-not-remember-my-security-questions-or-if-i-get-locked-out",
    "href": "13-faq.html#what-if-i-do-not-remember-my-security-questions-or-if-i-get-locked-out",
    "title": "15  13 Frequently Asked Questions (FAQ)",
    "section": "What if I do not remember my security questions or if I get locked out?",
    "text": "What if I do not remember my security questions or if I get locked out?\nYou would have to reach out to support at support@coleridgeinitiative.org to have your account unlocked and you would have to reset your security questions so that you can recover your account in the future.",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>13 Frequently Asked Questions (FAQ)</span>"
    ]
  },
  {
    "objectID": "13-faq.html#i-can-log-into-the-adrf-but-my-desktop-and-ds-application-just-show-blank-pages.",
    "href": "13-faq.html#i-can-log-into-the-adrf-but-my-desktop-and-ds-application-just-show-blank-pages.",
    "title": "15  13 Frequently Asked Questions (FAQ)",
    "section": "I can log into the ADRF but my desktop and DS application just show blank pages.",
    "text": "I can log into the ADRF but my desktop and DS application just show blank pages.\nPlease ensure the connection to ADRF is not being blocked by your organizations VPN and/or firewall (try using a device not connected to your organization’s network) and reach out to support@coleridgeinitiative.org.",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>13 Frequently Asked Questions (FAQ)</span>"
    ]
  },
  {
    "objectID": "13-faq.html#i-saved-a-file-in-the-c-drive-or-in-the-desktop.-when-i-logged-back-in-the-file-is-no-longer-there.-can-you-restore-it",
    "href": "13-faq.html#i-saved-a-file-in-the-c-drive-or-in-the-desktop.-when-i-logged-back-in-the-file-is-no-longer-there.-can-you-restore-it",
    "title": "15  13 Frequently Asked Questions (FAQ)",
    "section": "I saved a file in the C: drive or in the Desktop. When I logged back in, the file is no longer there. Can you restore it?",
    "text": "I saved a file in the C: drive or in the Desktop. When I logged back in, the file is no longer there. Can you restore it?\nThe ADRF is a temporary workspace environment, files left on the desktop will be removed when you log out of your session, and we cannot restore these files. See section Best practice is to store files in your user folder on the U: drive",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>13 Frequently Asked Questions (FAQ)</span>"
    ]
  },
  {
    "objectID": "13-faq.html#how-do-i-open-an-ipynb-notebook",
    "href": "13-faq.html#how-do-i-open-an-ipynb-notebook",
    "title": "15  13 Frequently Asked Questions (FAQ)",
    "section": "How do I open an ipynb notebook?",
    "text": "How do I open an ipynb notebook?\nOn the desktop you should find an icon for JupyterLab, when you click that, a command prompt and a browser window are opened up, leave the command prompt running. You should be able to open the file by selecting File -&gt; Open From Path and providing the path to the folder containing the ipynb notebook.",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>13 Frequently Asked Questions (FAQ)</span>"
    ]
  },
  {
    "objectID": "13-faq.html#how-can-i-ingest-publicly-available-data-into-the-adrf",
    "href": "13-faq.html#how-can-i-ingest-publicly-available-data-into-the-adrf",
    "title": "15  13 Frequently Asked Questions (FAQ)",
    "section": "How can I ingest publicly available data into the ADRF?",
    "text": "How can I ingest publicly available data into the ADRF?\nPlease open a support request by sending an email to support@coleridgeinitiative.org. Include the dataset you wish to have available inside the ADRF and documentation that confirms that the dataset is public.",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>13 Frequently Asked Questions (FAQ)</span>"
    ]
  },
  {
    "objectID": "13-faq.html#where-can-i-access-publicly-available-data-from-within-the-adrf",
    "href": "13-faq.html#where-can-i-access-publicly-available-data-from-within-the-adrf",
    "title": "15  13 Frequently Asked Questions (FAQ)",
    "section": "Where can I access publicly available data from within the ADRF?",
    "text": "Where can I access publicly available data from within the ADRF?\nPublicly available data is stored in the schema ds_public_1.",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>13 Frequently Asked Questions (FAQ)</span>"
    ]
  },
  {
    "objectID": "13-faq.html#where-is-my-project-or-training-related-data-stored",
    "href": "13-faq.html#where-is-my-project-or-training-related-data-stored",
    "title": "15  13 Frequently Asked Questions (FAQ)",
    "section": "Where is my project or training related data stored?",
    "text": "Where is my project or training related data stored?\nAll project and training related databases are prefixed with ‘pr_’ (for project) or ‘tr_’ (for training). You may use this space when creating intermediate datasets or as a “working space”. All project members have read and write access to this area (specific to your project).",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>13 Frequently Asked Questions (FAQ)</span>"
    ]
  },
  {
    "objectID": "13-faq.html#my-data-is-not-in-a-relational-format.-where-can-i-find-these-files",
    "href": "13-faq.html#my-data-is-not-in-a-relational-format.-where-can-i-find-these-files",
    "title": "15  13 Frequently Asked Questions (FAQ)",
    "section": "My data is not in a relational format. Where can I find these files?",
    "text": "My data is not in a relational format. Where can I find these files?\nRead-only non-relational data are stored in the G: drive on Windows Explorer. Project specific non-relational data and files are stored in project specific folders that are prefixed with ‘pr_’ or ‘tr_’. The location of these folders are in the P: drive on Windows Explorer.",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>13 Frequently Asked Questions (FAQ)</span>"
    ]
  },
  {
    "objectID": "13-faq.html#what-is-the-difference-between-the-p-u-and-g-drives",
    "href": "13-faq.html#what-is-the-difference-between-the-p-u-and-g-drives",
    "title": "15  13 Frequently Asked Questions (FAQ)",
    "section": "What is the difference between the P:, U: and G: drives?",
    "text": "What is the difference between the P:, U: and G: drives?\nEach drive location has a different purpose and access rule: - P: Project specific files shared by ALL project members - U: User personal space. Only the user has read/write access to this area. - G: Non-relational datasets. Read-only access to authorized users only.",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>13 Frequently Asked Questions (FAQ)</span>"
    ]
  },
  {
    "objectID": "13-faq.html#i-need-to-process-a-large-amount-of-relational-data.-what-is-the-destination-location",
    "href": "13-faq.html#i-need-to-process-a-large-amount-of-relational-data.-what-is-the-destination-location",
    "title": "15  13 Frequently Asked Questions (FAQ)",
    "section": "I need to process a large amount of relational data. What is the destination location?",
    "text": "I need to process a large amount of relational data. What is the destination location?\nThe best practice is to process the data where it is currently located. If the data is in a relational database, perform as much of your processing using Redshift to make the most efficient use of resources (i.e. filtering, sorting, etc).",
    "crumbs": [
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>13 Frequently Asked Questions (FAQ)</span>"
    ]
  },
  {
    "objectID": "dev-document.html",
    "href": "dev-document.html",
    "title": "16  ADRF User Guide",
    "section": "",
    "text": "17\nA detailed guide to help users navigate and use the Coleridge Initiative’s Administrative Data Research Facility (ADRF) effectively.\nLast Updated:\nObtaining ADRF Access",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>ADRF User Guide</span>"
    ]
  },
  {
    "objectID": "dev-document.html#table-of-contents",
    "href": "dev-document.html#table-of-contents",
    "title": "16  ADRF User Guide",
    "section": "Table of Contents",
    "text": "Table of Contents\n\nIntroduction\n\nObtaining ADRF Access\n\nOnboarding Modules and Security Training\nHow to Access and Use Your Project Workspace\nHow to Access Data\nWhere to Do Your Work\nHow to Work Collaboratively in the ADRF\nHow to Export Output from the ADRF\nDo’s and Don’ts for Discussing Data Hosted in the ADRF\nAdding Additional Packages in R/Python\nRedshift Querying Guide\nAccessing ADRF Dashboards\nFAQ",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>ADRF User Guide</span>"
    ]
  },
  {
    "objectID": "dev-document.html#introduction",
    "href": "dev-document.html#introduction",
    "title": "16  ADRF User Guide",
    "section": "1 Introduction",
    "text": "1 Introduction\nWelcome to the Coleridge Initiative’s Administrative Data Research Facility, or “ADRF” user guide. This is a living document intended to show new ADRF users how to use the platform for common tasks.\n\nAbout the Coleridge Initiative\nThe Coleridge Initiative’s mission is to improve the access, usability, and impact of data for public policy by fostering collaboration between government agencies, researchers, and other stakeholders. It aims to create a data ecosystem where government data can be more effectively used to inform evidence-based decision-making, policy development, and research.\n\n\nAbout the Administrative Data Research Facility\nThe Administrative Data Research Facility (ADRF) is a platform provided by the Coleridge Initiative that enables researchers to access and analyze administrative data from government agencies securely and efficiently. It offers a secure computing environment where researchers can work with sensitive data while ensuring privacy and confidentiality. The ADRF provides tools and infrastructure for data integration, analysis, and visualization, allowing researchers to conduct rigorous and reproducible studies using large-scale administrative datasets. By facilitating access to valuable data resources and promoting collaboration between researchers, government agencies, and other stakeholders, the ADRF supports evidence-based policymaking and advances research in fields such as public health, education, labor economics, and social policy.\n\n\nThe Five Safes Security Framework\nThe ADRF follows the Five Safes Framework, a data management framework commonly used in government agencies, to ensure the safe use of sensitive and confidential data assets. It considers five dimensions in making data-related safety and security decisions: Safe Projects, Safe People, Safe Settings, Safe Data, and Safe Exports.\n\n\n\nThe Five Safes Security Framework\n\n\n\nSafe Projects - The ADRF contains only agency approved projects that have been proposed and agreed upon by project and dataset stewards. Only approved projects are housed within ADRF, only approved individuals are granted access to a given project, and project environments are kept separated from each other. These approved projects require signed agreements and only approved users can access the project workspaces within the platform.\nSafe People - Only approved researchers are permitted to access project workspaces and related resources. Each individual with approved access must complete security training, agree to the ADRF terms of use, and sign relevant data use agreements. Individuals must authenticate to gain access to the remote platform and all ADRF activity is monitored.\nSafe Settings - The ADRF is designed to provide secure methods of data transfer for agency micro-data, specifically data that includes Personally Identifiable Information. Only agency identified and authorized personnel are invited to perform data transfers.\nSafe Data - Before transmission to ADRF, all data with personally identifiable or other sensitive information is hashed, and an online data stewardship application provides data stewards with information on who is accessing their data, how it is being accessed, what projects employ it, the characteristics of each data asset, and the status of user agreements.\nSafe Exports - Users are prevented from unauthorized removal of any information within the secure environment.",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>ADRF User Guide</span>"
    ]
  },
  {
    "objectID": "dev-document.html#obtaining-adrf-access",
    "href": "dev-document.html#obtaining-adrf-access",
    "title": "16  ADRF User Guide",
    "section": "2 Obtaining ADRF Access",
    "text": "2 Obtaining ADRF Access\n\nTopics\n\nAccount Setup\nObtaining ADRF Access\nAccount Registration and Onboarding\nMore Information\n\n\n\nAccount Setup\n\nAgency-affiliated researcher. If you are an agency-affiliated researcher, your agency will set up an ADRF account for you.\nIndividual part of a training program. If you are part of a training program, the Coleridge Initiative team will create an account for you once you have been accepted into the program.\n\n\n\nObtaining ADRF Access\n\nAgency-affiliated researcher. If you are an agency-affiliated researcher using an agency-sponsored account, you will be granted ADRF access once you complete your onboarding tasks and required data access agreements. If you are a self-paying agency-affiliated researcher, your ADRF access is conditional on receipt of payment. If your institution of Office of Sponsored Programs will be submitting payment on your behalf, please be aware of potential access delays. Whenever possible, the Coleridge Initiative advises paying with a personal credit card or institutional payment card and using the generated invoice to request reimbursement.\nIndividual part of a training program. If you are part of a training program, you will be granted ADRF access once you complete your onboarding tasks and required data access agreements.\n\n\n\nAccount Registration and Onboarding Tasks\n\nYou will receive an email invitation to activate your account. The email will come from http://okta.com, so please make sure that it doesn’t get caught in your email spam filter. Follow the steps outlined in the email to set up your password and your multi-factor authentication preferences. Clink on the link below to watch a video walking through the steps.\nAfter activating your account, you will be logged in to the ADRF Applications page. Proceed to the Management Portal by clicking on the icon.\nIn the Management Portal, you will notice a “Onboarding Tasks” section within “Admin Tasks” with a number of items you will need to complete before you can gain access to the project space. Refer to the next section for details about the onboarding process.\n\n\n\nMore Information\nIf you have any questions, please contact support@coleridgeinitiative.org.",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>ADRF User Guide</span>"
    ]
  },
  {
    "objectID": "dev-document.html#onboarding-modules-and-security-training",
    "href": "dev-document.html#onboarding-modules-and-security-training",
    "title": "16  ADRF User Guide",
    "section": "3 Onboarding Modules and Security Training",
    "text": "3 Onboarding Modules and Security Training\n\nTopics\n\nManagement Portal\nSigning the ADRF Terms of Use Agreement\nWatching the Security Training Video\nComplete the Security Training Quiz\n\n\n\nManagement Portal\nThe Management Portal web-based application is positioned primarily as the management and monitoring console for project and data stewards. It provides detailed insight on project configurations, user activity, user onboarding status, and overall cost of a project on the ADRF. We focus on four primary pillars of information a Project/Data Steward most often focuses on: - People – Who are the members of projects, how often do they use the ADRF, what exports have they requested and their status, estimated cost per person/project for current month and for the project since inception, and detailed usage metrics. - Projects – Details of project start/end dates, abstract description, number of members onboarded and pending, and resources the project has access to (i.e. datasets, etc). - Datasets – Description of the dataset, location on the ADRF (database or file system), size, name of the data steward(s), and the link to Enterprise Data Catalog (Informatica) describing the dataset and metadata. - Agreements – What agreements are related to these projects, indication of each member’s signing status, members pending signature, and term (dates) covered by the agreement(s).\nAs mentioned, the Management Portal application will track your ADRF usage. The protal will also consolidate your ADRF Terms of Use, Security Training Quiz, and Security Training Video into one place. In order to complete ADRF onboarding, all three of the mentioned tasks are to be completed by the user (researcher). To access the Management Portal, log in using your credentials at https://adrf.okta.com and click on the ADRF Management Portal icon:\n\n\n\nOnce inside the Management Portal, you have access to your personal workspace sessions statistics along with admin tasks such as the three onboarding tasks and password management. See the example below:\n\n\n\n\n\nAccessing the Onboarding Tasks\nTo gain access to your ADRF project workspace, you must first complete 3 required ADRF onboarding tasks: 1. Signing the ADRF Terms of Use agreement. Users must comply with the Terms of Use when working in the ADRF. The Agreement covers rules of behavior within ADRF and guidelines for discussing ADRF content prior to passing disclosure review. It asks users to agree to a series of principles governing dataset use, behavior, and data export procedures, and to acknowledge the consequences of violating the Terms. 2. Completing security awareness training. Users will get access to a security awareness video and should confirm that they have reviewed the video. The video covers security content that is then assessed during the security awareness quiz. 3. Passing the security awareness quiz. The security awareness quiz consists of a set of 6 questions. Users must achieve a score 5 out of 6 to pass the quiz. Unsuccessful users can retake the quiz to achieve a passing score.\nFollow the steps below to access the ADRF Onboarding Tasks: 1. Log in to the Management Portal\n\nClick on “Admin Tasks” in the left navigation menu.\n\n\n\n\n\nClick on “Complete Onboarding”.\n\n\n\n\n\nThis will load the Onboarding Tasks window.\n\n\n\n\n\nClick on each individual task to complete it.\n\n\n\nSigning the ADRF Terms of Use Agreement\nThe Terms of Use need to be completed before you are given access to the data and project space inside the ADRF. To complete ADRF Terms of Use, complete the following steps:\n\nClick on the “Terms of Use” tile.\n\n\n\n\n\nClick on “Sign with DocuSign”\n\n\n\n\n\nYou will then be redirected to the DocuSign signing page. Click “Continue” on the upper right corner.\n\n\n\n\n\nClick “Start” to begin.\n\n\n\n\n\nIf you have already configured a signature, click on the yellow “Sign” button to apply it. Otherwise, follow the prompts to configure your electronic signature.\n\n\n\n\n\nOnce the signature is applied, click “Finish”.\n\n\n\n\nYou will then be redirected back to the management portal. And the “Terms of Use” task will be marked as completed.\n\n\nWatching the Security Training Video\nThe Security Training Video needs to be completed as well. To complete the training, complete the following steps:\n\nClick on the “Security Training Video” tile to load the player and then click play.\nOnce you have watched the video in its entirety, click on the “Mark as Complete” button to complete the task. Note: the “MARK AS COMPLETE” button will not be enabled until at least 5 minutes have passed since the start of the video.\nClick on the back arrow in the upper right corner to return to the main tasks panel.\nThe training video section will now be marked as completed.\n\n\n\nComplete the Security Training Quiz\nThe Security Training Quiz needs to be completed after the Security Training Video. To complete the training, complete the following steps:\n\nClick on the “Security Quiz” tile to load the quiz.\n\n\n\n\n\nAnswer the questions and click on the “SUBMIT RESPONSE” button. You must answer at least four of the questions correctly to complete this task.\n\n\n\n\n\nYou will be automatically redirected to the main task panel once the questionnaire has been successfully completed. And the “Security Quiz” will be marked as completed.",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>ADRF User Guide</span>"
    ]
  },
  {
    "objectID": "dev-document.html#how-to-access-and-use-your-project-workspace",
    "href": "dev-document.html#how-to-access-and-use-your-project-workspace",
    "title": "16  ADRF User Guide",
    "section": "4 How to Access and Use Your Project Workspace",
    "text": "4 How to Access and Use Your Project Workspace",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>ADRF User Guide</span>"
    ]
  },
  {
    "objectID": "dev-document.html#topics-2",
    "href": "dev-document.html#topics-2",
    "title": "16  ADRF User Guide",
    "section": "### Topics",
    "text": "### Topics\nA project workspace is a secure, isolated virtual environment in the ADRF within which an approved set of users can access a defined number of agency datasets. The project workspace is designed to allow approved researchers to access, analyze, and manipulate specific datasets relevant to their approved projects while maintaining strict data confidentiality and integrity.\nProject workspace in the ADRF are isolated from each other. Even if a person is granted access to two project workspaces, the user can not access or copy files from one into the other. This is important because the two project workspaces might have access to different datasets.\n\nLogging into and Logging out of the ADRF\nThis video linked below runs through the necessary steps for logging into and logging out of the ADRF.\nTo watch the video, right-click the image below and choose “Open link in new tab” (by right-cicking, you will avoid leaving this page).\n\n\n\nLogging into ADRF\n\n\n\n\nVirtual Desktop Environment\n\nWhat is a VDE?\nA virtual desktop environment (VDE) allows you to interact with a remote system as if it were your own personal computer. The majority of your standard desktop functions are available, but the programs, data, and permissions are all controlled by the remote administrator (Coleridge Initiative). Thus, you will be working in a familiar environment while accessing protected data, programs, and systems that would otherwise be difficult to distribute. The ADRF uses a standard Windows environment (Windows Server) and provides a variety of software packages to conduct your analysis. For more on Windows capabilities, see the section on Windows Settings.\n\n\n\n\n\nTemporary Nature of the Environment\nWhile the environment is similar to that on your home computer (for Windows users), there are a handful of key differences. The first is that the environment is temporary in nature. This means that if you are not using it for a prolonged period of time (default is four hours but can vary by project), running programs will stop running and the information stored in temporary locations will be deleted. You will receive on on-screen message before any sessions are terminated. For more on safe, non-temporary storage locations in the ADRF, see the section on Storing Analytic Results.\nGiven the temporary nature of the ADRF, it is crucial to make sure that your work is saved—and saved in an appropriate location. Once this is complete and you are finished working, make sure that you log out of the ADRF instead of closing the window. To do this, click the rightmost icon on the top taskbar to open up the dropdown menu and select End Session. You will be prompted to double-check that your work is saved prior to ending your session and confirm that you want to end your session.\n\n\nModifying the Environment\n\nEstablishing Personal Folders\nEstablishing your own personal folders is one of the simplest, yet most important, steps to take when setting up your environment. As we note in the section on Storing Analytic Results, the two possible places to store your analytic results or files are in either the U: drive or the P: drive.\nYou will find your personal folder in the U: drive. The folder name will include your Firstname and Lastname, and may additionally include your project workspace number. This is a personal workspace that only you can access in the ADRF.\n\n\nThe U: Drive and the P: Drive\nThe U: drive is your user drive; it’s where you will store any files you are working on. Only the user will have access to the U: drive. For example, if user A wants to share information with user B who is on the same project, user A will need to save files to a P: drive folder and not folders in their U: drive since user B will not be able to access user A’s U: drive.\nThe P: drive is the project drive, which will be used to house project-specific folders. Thus, you and other collaborators on the same project will be able to save files to project drive folders.\nBoth the U: drive and P: drive have defined resource limitations of 150GB. When the workspace exceeds these limits, users will not be able to create new files or save data. The ADRF will not alert users when they approach on 150GB used. Users can check their current usage by right clicking on the user folder and clicking on properties.\n\n\nOther Modifications\nThe top taskbar contains shortcuts to the command prompt, multiple desktop windows, a temporary folder, settings, full-screen view, and toggling multiple monitors.\n\n\n\n\n\n\nWindows Settings\nYour desktop will look familiar if you are a Windows user. You will have icons for quick access to programs or browsers on your desktop. The windows icon on the bottom left side of the screen will open up a menu of programs, folders, and other tools, much as you would see on your own desktop. You will have access to PowerShell and several customization settings (e.g., remove bottom taskbar).\n\n\n\n\n\n\nSoftware in the ADRF\n\nJupyterLab\nJupyterLab provides flexible building blocks for interactive, exploratory computing. While JupyterLab has many features found in traditional integrated development environments (IDEs), it remains focused on interactive, exploratory computing. For more on JupyterLab, see the interface documentation.\nThe JupyterLab interface on the ADRF consists of a main work area containing tabs of documents and activities, a collapsible left sidebar, and a menu bar. The left sidebar contains a file browser, the list of running terminals and kernels, the table of contents, and the extension manager.\n\n\n\nWhen using Jupyter Notebooks, make sure that all your work is saved to your U: drive and the correct director within the U: drive. You can “nd the active directory by reading the path displayed in the file browser. By default, JupyterLab opens with your U: drive as the base directory. Below, the folder icon in the white box is my user folder (not displayed, but titled Firstname.Lastname; you will have already set up your folder) and subfolder WDQI.\n\n\n\n\nNotebooks\nJupyter Notebooks are documents that combine live runnable code with narrative text (Markdown), equations (LaTeX), images, interactive visualizations, and other rich output. You can create a notebook by clicking the blue + button in the file browser and then selecting a kernel (R, Python3, Stata) in the Launcher tab. For more information on getting started with Jupyter Notebooks, see JupyterLab Notebook documentation.\n\n\nAccessing Stored Data from a Notebook\nA common question is how to access stored data while writing to and using a Jupyter Notebook. Data in the ADRF are stored in a database using Microsoft SQL Server. For more information on how to access stored data in the ADRF based on choice of program (Python, R, Stata), see the section on Accessing Your Data.\n\n\n\nPython 3\nPython is a general-purpose programming language. You can access Python in a multitude of ways:\n\nThrough JupyterLab. This is the recommended way to access Python since it has packages installed and available, and an execution environment for testing and running code (as well as a place to write and save code). Open JupyterLab and make sure your directory is set appropriately in the “le browser. Once there, in your new Launcher window, click the Python 3 icon.\n\n\n\n\n\nThrough the start menu (windows icon). Type in Python. A desktop app called Python 3.7 (64-bit) will populate a window where you can begin programming.\n\n\n\n\n\nThrough the command prompt in the top taskbar. Once the command prompt window is open, type in python.\n\n\n\n\n\nThrough Pycharm\n\n\n\n\n\n\nR\nR is a general-purpose programming language. You may access R in one of three ways:\n\nThrough RStudio. This is an integrated development environment (IDE) for R. You can run R code, display variables, debug R code, do inline visualizations, and more. Open RStudio through the desktop shortcut, or type RStudio in the start menu.\n\nThrough JupyterLab. Open JupyterLab and make sure your directory is set appropriately in the file browser. Once there, in your new Launcher window, click the R icon.\n\n\n\n\nUsing R in JuypterLab\n\n\n\nThrough the R GUI (graphical user interface). Type R in the search bar and click to open the RGui.\n\n\n\nStata\nStata is a general-purpose statistical so#ware package. Stata can be accessed through the desktop shortcut StataMP 16 or by searching for it using the search or menu bar, or through JupyterLab.\n\n\nDBeaver\nDBeaver is a universal tool for querying, editing, and managing data stored in Redshift databases. The ADRF stores data using AWS Redshift Server. DBeaver can be accessed through the desktop shortcut DBeaver or by looking it up using the search bar.\nOnce open, you will need to connect to a Redshift server. Please follow the directions in the Redshift Querying Guide to connect to the appropriate server.",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>ADRF User Guide</span>"
    ]
  },
  {
    "objectID": "dev-document.html#how-to-access-data",
    "href": "dev-document.html#how-to-access-data",
    "title": "16  ADRF User Guide",
    "section": "5 How to Access Data",
    "text": "5 How to Access Data\nThis section provides information on how to locate the secure data you’ve been approved to access in the ADRF.\nThe ADRF offers both unstructured and structured data storage. Data stored in databases are located in the ADRF’s structured data storage. Other forms of data, such as flat files, CSVs, documentation, etc. are stored in the ADRF’s unstructured data storage. - Accessing data stored in unstructured data storage - Accessing data stored in structured data storage\nExternal Data and Code: Please note that importing of external data and code is restricted to only Coleridge staff. Given the secure and protected environment provided by the ADRF, all code, data, and packages that are coming from outside of the ADRF must be carefully vetted to prevent leaks, disclosure, or unauthorized access. This means that there is no direct method for uploading data or code from your system to the ADRF. Please contact support@coleridgeinitiative.org for any questions or assistance on importing your own code, data, or packages.\n\nAccessing data stored in unstructured data storage\nUnstructured data, such as CSVs, Stata DTAs, SAS data, are stored in the “G” drive. Project teams will have read-only access to the data folders in this drive that they have been approved to access.\nThe G: Drive is located in the ADRF’s file system. You can find it by going to the Folder icon in the Windows Task Bar. \n\n\nAccessing data stored in structured data storage\nStructured data, or data that are stored in relational databases, are stored in AWS Redshift, an MPP platform that is built on SQL and is specifically designed to handle larger data assets. Users access structured data either through DBeaver – the ADRF’s Database Access tool – or by porting directly to Redshift through their preferred statistical package (like R, or Python).\nFor detailed instructions on how to access data in structed data storage, please see the ADRF’s Redshift Querying Guide",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>ADRF User Guide</span>"
    ]
  },
  {
    "objectID": "dev-document.html#where-to-do-your-work",
    "href": "dev-document.html#where-to-do-your-work",
    "title": "16  ADRF User Guide",
    "section": "6 Where to Do Your Work",
    "text": "6 Where to Do Your Work\nThe sensitive data that you have been approved to access will either be stored in the ADRF’s structured or unstructured stroage locations (see How to Access Data](#5-how-to-access-data)).\n\nEligible locations to do your work\nYou can perform your approved project work in one of the following locations in the ADRF: - User Drive - Project Drive - PR schema\n\nUser Drive\nThe U: drive is your user drive; it’s where you will store any files you are working on. Only the user will have access to the U: drive. For example, if user A wants to share information with user B who is on the same project, user A will need to save files to a P: drive folder and not folders in their U: drive since user B will not be able to access user A’s U: drive.\n\n\nProject Drive\nThe P: drive also allows permanent storage. This drive is accessible by anyone on the same project, but not across projects. This is the only drive outside of the user drive where saved files will not be erased after logging out of the ADRF.\n\n\nPR Schema\nEach project will have a project-specific database created. All members of the project will have read and write permissions for data and may also create their own objects (tables, etc.). The project databases are prefixed with pr-.\n\n\n\nIneligible locations to do your work\nThe G: drive (data), the L: drive (Libs), and the desktop are not eligible for long-term file storing. You won’t have permissions to write to either the G: drive or the L: drive. The desktop will function only as temporary storage—as soon as a user is logged out of the ADRF, your desktop will be cleared. Additionally, since Wi-Fi connectivity can be imperfect, desktop storage for any amount of time is not recommended.\n\n\nStorage Size Restrictions and Best Practices\nStorage size varies by project, but is capped at a predetermined amount. Additional storage costs may vary depending on the resource requirements.\nBest Practices: - To save storage space, avoid saving copies of raw data tables. Instead, write code to access data. For detailed instructions on how to access data in structed data storage, please see the ADRF’s Redshift Querying Guide - Organize folders in a way that makes sense for your particular project. For example, you might have folders for a particular analysis or sub-projects. Dates on file names can be helpful for version control. - Keep tabs on how much storage you are using compared to the allocated amount of storage.",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>ADRF User Guide</span>"
    ]
  },
  {
    "objectID": "dev-document.html#how-to-work-collaboratively-in-the-adrf",
    "href": "dev-document.html#how-to-work-collaboratively-in-the-adrf",
    "title": "16  ADRF User Guide",
    "section": "7 How to Work Collaboratively in the ADRF",
    "text": "7 How to Work Collaboratively in the ADRF\n\nShared Folders\nShared folders within a project are a great way to share information with other members on a team project. Remember that when working with teams you may not share the ADRF screen (even project folders) with other members on video platforms or otherwise, whether or not your team members are working on the same project.\n\n\nSharing Restrictions\nAgain, remember that when working with teams you may not share the ADRF screen with other members on video platforms or otherwise, whether or not your team members are working on the same project.\nThe information contained in the ADRF is restricted to reside only in the ADRF for all purposes unless it passes Export Review. This means that it cannot be shared or potentially shared with any unauthorized parties. Do not write down any numbers or figures or tables corresponding to data in the ADRF. Copying and pasting is restricted, but manually circumventing this is also not permitted by your data agreements.",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>ADRF User Guide</span>"
    ]
  },
  {
    "objectID": "dev-document.html#how-to-export-output-from-the-adrf",
    "href": "dev-document.html#how-to-export-output-from-the-adrf",
    "title": "16  ADRF User Guide",
    "section": "8 How to Export Output from the ADRF",
    "text": "8 How to Export Output from the ADRF\nTo provide ADRF users with the ability to draw from sensitive data, results that are exported from the ADRF must meet rigorous standards meant to protect privacy and confidentiality. To ensure that those standards are met, the ADRF Export Review team reviews each request to ensure that it follows formal guidelines that are set by the respective agency providing the data in partnership with the Coleridge Initiative. Prior to moving data into the ADRF from the agency, the Export Review team suggests default guidelines to implement, based on standard statistical approaches in the U.S. government 1,2 as well as international standards 3, 4, and 5. The Data Steward from the agency supplying the data works with the team to amend these default rules in line with the agency’s requirements. If you are unsure about the review guidelines for the data you are using in the ADRF or if you have any questions relating to exports, please reach out to support@coleridgeinitiative.org before submitting an export request.\nTo learn more about limiting disclosure more generally, please refer to the Big Data and Social Science textbook or right-click here to view Coleridge’s Privacy and Confidentiality video series.\nNote: The Export Requester cannot be assigned as a reviewer of the same export.\n\nGeneral Best Practices for a Successful Export\nNote: Currently, the review process is highly manual: Reviewers will read your code and view your output files, which may be time-consuming.\n\nEach additional release adds disclosure risk and therefore limits subsequent releases; we ask that users limit the number of files they request to export to just the outputs necessary to produce a particular report or paper. If you are requesting an export of more than 10 files, there may be an additional charge.\nThe reviewers may ask you to make changes to your code or output to meet the requirements of guidelines that have been given by the providers of the data in the ADRF. Thus, we strongly encourage you to produce all output files—tables with rounded numbers, graphs with titles, and so forth—through code, rather than manually.\nWe ask that you only request review of final versions of output files, rather than in-progress versions. Any file containing intermediate output will be rejected.\nEvery code file should have a header describing the contents of the file, including a summary of the data manipulation that takes place in the file (e.g., regression, table or figure creation, etc.).\nDocumenting code by using comments throughout is helpful for disclosure reviews. The better the documentation, the faster the turnaround of export requests. If data files are aggregated, please provide documentation on the level of aggregation and for where in the code the aggregation takes place.\nTo help reviewers, who may not have seen your code before, we ask that users create meaningful variable names. For instance, if you are calculating outflows, it is better to name the variable “outflows” than to name it “var1.”\n\n\n\nTimelines for Export Process\n\nColeridge reviewers have five business days to complete an export from the day you submit an export request. However, timelines may differ depending on your agency, so please refer to your specific agency’s guidelines.\nThe review process can be delayed if the reviewer needs additional information or if the reviewer needs you to make changes to your code or output to meet the ADRF nondisclosure requirements.\n\n\n\nExport Review Process\nThe ADRF Export Review process typically involves two main stages:\n\nPrimary Review: This is an initial, cursory review of your documentation and exports to ensure they do not include micro-data. A primary review can take up to 5 business days, so please plan accordingly when submitting your materials. In cases where the reviewer has questions or requires additional information, the primary review may extend beyond 5 business days.\nSecondary Review: This is a comprehensive review conducted by an approved Data Steward who has content knowledge for the data permissioned to your workspace. If your submission pertains to multiple data assets, it will require approval by each Data Steward before the material can be exported from the ADRF. Please plan accordingly.\n\n\n\nHow to Check Your Export Review Status:\nIf you’ve submitted an export request, you can easily check the status of your submission by following these steps:\n\nLog into the ADRF.\nOpen the ADRF Export module.\n\n\nReview status descriptions\nTo help you better understand the different stages of the Export Review process, here are the status descriptions you may encounter: 1. Awaiting Reviewer: Your export is currently under primary review. If any issues arise during the primary review, your reviewer will notify you. Upon completion of the primary review, the secondary reviewer(s) will be notified. 2. Awaiting Secondary Review: Your export is currently under secondary review. If your submission pertains to multiple data assets, it will require a review by each Data Steward before being approved.\n\n\n\nPreparing Data for Export\nEach agency has specific disclosure review guidelines, especially with respect to the minimum allowable cell sizes for tables. Refer to these guidelines when preparing export requests. If you are unsure of what guidelines are in place for the dataset with which you are working in the ADRF, please reach out to support@coleridgeinitiative.org\n\nTables\n\nCell Sizes:\n\nFor individual-level data, please report the number of observations from each cell. For individual-level data, the default rule is to suppress cells with fewer than 10 observations, unless otherwise directed by the guidelines of the agency that provided the data.\nIf your table includes row or column totals or is dependent on a preceding or subsequent table, reviewers will need to take into account complementary disclosure risks—that is, whether the tables’ totals, or the separate tables when read together, might disclose information about individuals in the data in a way that a single, simpler table would not. Reviewers will work with you by offering guidance on implementing any necessary complementary suppression techniques.\n\nWeighted Data: If weighted results are to be exported, you must report both weighted and unweighted counts.\nRatios: If ratios are reported, please report the number of valid cases for both the numerator and the denominator (e.g., number of men in state X and number of women in state X, in addition to the ratio of women in state X).\nPercentiles: Do not report exact percentiles. Instead, for example, you may calculate a “fuzzy median,” by averaging the true 45th and 55th percentiles.\nPercentages: For any reported percentages or proportions, the underlying counts of individuals contributing to the numerators and denominators must be provided for each statistic in the desired export.\nMaxima and Minima:\n\nSuppress maximum and minimum values in general.\nYou may replace an exact maximum or minimum with a top-coded value.\n\n\n\n\nGraphs\n\nGraphs are representations of tables. Thus, for each graph (which may have, e.g., a jpg, pdf, png, or tif extension), provide the source data of the underlying table of the graph following the guidelines for tables above.\nBecause graphs and other figures take the most time to review, the number of generated graphs should be as low as possible. Please consider the possibility that you could export the underlying table instead, and generate the graph in another package.\nIf a graph is produced from aggregated data or from tables that have been disclosure-proofed following the guidelines above (e.g., bar charts of magnitudes), provide the underlying tables.\nIf a graph is produced directly from unit-record data but aggregated in the visualization (e.g., frequency histograms), provide the underlying tables.\nIf a graph is produced directly from unit-record data and displays unit-record values (e.g., scatterplots, plots of residuals), the graph can be released only after you ensure that individuals cannot be re-identified and that values can only be estimated with a high level of uncertainty. Further processing to meet this requirement can include, but is not restricted to, cutting off the tails of a distribution, removing outliers, jittering the actual values, and removing or modifying axis values.\nIf a graph is produced from the results of modeling or derivation and uses the unit-record data (e.g., regression curves), the graph can be released only if the values cannot be used to find original data values.\n\nGraphs of this type are generally automatically cleared.\nFor precision/recall graphs, you will need to report the sample size used to generate your model(s).\n\n\n\n\nModel Output\nOutput from regression or machine-learning models generally does not pose a risk of disclosing personally identifiable information, as long as the models are not based on small samples. Provide the counts for each variable that produces the model output. If categorical variables are used then provide the counts for each category.\n\n\n\nSubmitting an Export Request\nTo request an export be reviewed, please follow the instructions below or you can watch an instructional video by right-clicking this link.\n\nLog into the ADRF (http://adrf.okta.com).\nInput your login credentials.\nVerify yourself with Okta (download Okta Verify on your smartphone or other device).\nChoose your project as seen in the photo below. For the purpose of this document, you are seeing the Coleridge Initiative Associate Access project. \nSelect Desktop and login with the same credentials you had done previously.\nUpon entering the ADRF, a Google Chrome page will appear as shown in the photo below (the Getting Started page). On this page, click on the Export Request tile. Or, from the ADRF desktop, open Google Chrome and navigate to export.adrf.net. (Note: export.adrf.net is an address that will only work within the ADRF desktop). \nClick My Requests, or the top (person-shaped) icon, at the left side of the window as shown in the screenshot below. \nClick New Item as shown below \n\n\nYou will be asked to select the project to which your export relates. If you do not see the correct project listed in the dropdown list, please reach out to our support team at support@coleridgeinitiative.org.\n\n\nAfter selecting a project, click Continue. \nRead through the entire page that loads. This page, titled “Create Export Request,” will ask for you to comment on all supporting code files to explain the commands used to generate the files in the export request. The Export Review team will reject all requests containing intermediate output. The Export Review team will typically release export requests within five business days. However, if the team has any clarifying questions, this could result in a longer review process. You need to document your output files in the text box provided. See the example below: \nWhen you have read through and followed the page instructions, and are ready to proceed:\n\n\nMove the slider at the bottom of the page to indicate that you have followed the page’s guidelines.\nAt the bottom of the page, upload each of the files that you have prepared.\nClick Submit Request… to create the export request. \n\n\nYou can click My Requests at the left side of the window to view your current and previous export requests.\n\nNote: To learn more about exporting results, you can watch an instructional video by right-clicking this link.",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>ADRF User Guide</span>"
    ]
  },
  {
    "objectID": "dev-document.html#dos-and-donts-for-discussing-data-hosted-in-the-adrf",
    "href": "dev-document.html#dos-and-donts-for-discussing-data-hosted-in-the-adrf",
    "title": "16  ADRF User Guide",
    "section": "9 Do’s and Don’ts for Discussing Data Hosted in the ADRF",
    "text": "9 Do’s and Don’ts for Discussing Data Hosted in the ADRF\nYou must protect the confidential data that is hosted inside the ADRF in communicating with your teammates. The general rule is that you should never take any exact number out of the ADRF. This means you should never write down or share any number by text, screenshot, or share an image even with a team-mate. The rules have become more complicated now that everything is online, because even though your teammates are “safe people”, and Zoom conversations are password protected and encrypted, we’d rather err on the side of caution when sharing information over Zoom.\nTo ensure safe outputs, the Coleridge Initiative works with an agency’s Data Steward to develop rigorous export review requirements catered to the specific needs of the partner agency. While you should make sure to acquaint yourself with the specific export rules associated with the confidential data you have been approved to access, cheat sheet provided below summarizes some of the rules that apply to discussing data before it has been exported from the ADRF and passed the ADRF team’s disclosure review.\nIf you are unsure about a specific situation, please ask reach out to the Coleridge Support Team at support@coleridgeinitiative.org.\n\nExact Numbers\nDo not describe a statistic in exact numbers. If you would like to communicate these values while not in person, you can have a private discussion via the projects drive inside the ADRF.\nExample: If an average within a specific group was 5,000, you would need to convey this average on the projects drive.\n\n\nComparing Values\nWhen comparing values, you are permitted to say that one value is more than, less than, or about the same as another. However, you cannot refer to the exact difference between the two numbers.\nIn practice, you can use pluses and minuses to convey differences between values for data that has not been exported from the ADRF.\nExample: “The mean for Group A was roughly the same as the mean for Group B, but these values were both greater than that of Group C.”\n\n\nPercentages/Proportions\nPercentages and proportions also cannot be directly mentioned. Instead, you can refer to the percentage/proportion within 25%.\nExample: If a proportion was 30%, you could say “The proportion is about 25%” or “The proportion is between 25% and 50%.”",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>ADRF User Guide</span>"
    ]
  },
  {
    "objectID": "dev-document.html#adding-additional-packages-in-rpython",
    "href": "dev-document.html#adding-additional-packages-in-rpython",
    "title": "16  ADRF User Guide",
    "section": "10 Adding Additional Packages in R/Python",
    "text": "10 Adding Additional Packages in R/Python\nThe ADRF has an internal package repository, so users can install packages for R and Python themselves.\nThe repositories that are currently mirrored in the ADRF are CRAN for R packages and PyPi.org for Python. There is currently no access to packages hosted on Github or other mirrors.\nNote: If you are working in a shared workspace for a project, each user in the project must install the packages, there is no shared package installation for projects.\n\nAdd additional R packages\nTo install R packages, simply use the code below and the package will be installed from the repository. You will not have to re-install the package again, and to use the package load it with the library() function. For example:\ninstall.packages(\"packagename\")\n** Example**: Installing tidyverse \nTo install a specific package version you can specify:\ninstall.packages(\"remotes\")\n\nremotes::install_version(\"tidyverse\", \"1.3.2\")\nNote: We recommend starting R using Rstudio for best results, instead of double clicking on a R or Rmarkdown script.\n\n\nAdd additional Python packages\nSimilar to R packages, Python packages may be installed using the Package Installer for Python (pip).\nNote: We recommend installing python packages from the command line. If you start Jupyter lab, and choose the Terminal tab:\n\n\n\nIf you start Juypter Lab, choose the Terminal tab\n\n\nThen install your package using pip, for example, to install the pandas package:\n\n\n\nExample: pandas package installation\n\n\nThen you may use the package within your Jupyter notebook as usual.\nTo install a specific package version type:\npip install pandas==1.2.3",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>ADRF User Guide</span>"
    ]
  },
  {
    "objectID": "dev-document.html#redshift-querying-guide",
    "href": "dev-document.html#redshift-querying-guide",
    "title": "16  ADRF User Guide",
    "section": "11 Redshift Querying Guide",
    "text": "11 Redshift Querying Guide\nThis document serves as an introduction to generating proficient Amazon Redshift queries. This is a generalized document meaning you will need to replace “schema_name” and “table_name” with the appropriate schema and table names used for your project.\nNote: All data is stored under schemas in the projects database.\n\nTopics\n\nData Access\nUsing DBeaver to access a database\n\nCreating tables in a PR or TR schema in Dbeaver\n\nConnecting to a database through a statistical program using an ODBC connection\n\nConnecting to a database using SAS\nConnecting to a database using R\nConnecting to a database using Python\nConnecting to a database using Stata ### Data access If you are approved to access data that are stored in a database, the data are housed in Redshift. To access those data, you will have to log in to Redshift within your workspace.\n\n\nYou need to replace the “user.name.project” with your project workspace username. The project workspace username is your user folder name in the U:/ drive:\n\n\n\nImage of Project-Based User Name\n\n\nNote: You will need to enter your specific user name when logging into Redshift. The password needed to access Redshift is the second password entered when logging into the ADRF as shown in the screen below: \n\n\nUsing DBeaver to access a database\nTo establish a connection to Redshift in DBeaver, first open DBeaver by clicking on the DBeaver icon located on the ADRF desktop and then double click on the server you wish to connect to. Note: All data is stored under schemas in the projects database.\nIn the example below, we will connect to Redshift11_projects. After double clicking on Reshift11_projects, a window will appear asking for your Username and Password. - In Username, enter “adrf\\” followed by your project workspace username - In Password, enter the password associated with your project workspace username \nAfter completing the Username and Password fields, click OK. You will now have access to your data stored on the Redshift11_projects server.\nNote: Please make sure to enter “adrf\\” before your project workspace username in the Username field. If you do not enter “adrf\", or accidently include a”/” instead of a “\\”, you will not be able to connect to Redshift. If you are having trouble connecting, an incorrect entry in Username is most likely the culprit.\n\nCreating tables in a PR or TR schema in Dbeaver\nWhen users create tables in their PR (Research Project) or TR (Training Project) schema, the table is initially permissioned to the user only. This is analogous to creating a document or file in your U drive: Only you have access to the newly created table.\nIf you want to allow all individuals in your project workspace to access the table in the PR/TR schema, you will need to grant permission to the table to the rest of the users who have access to the PR or TR schema.\nYou can do this by running the following code: GRANT SELECT, UPDATE, DELETE, INSERT ON TABLE schema_name.table_name TO group db_xxxxxx_rw;\nNote: Note: In the above code example replace schma_name with the pr_ or tr_ schema assigned to your workspace and replace table_name with the name of the table on which you want to grant access. Also, in the group name db_xxxxxx_rw, replace xxxxxx with your project code. This is the last 6 characters in your project based user name. This will start with either a T or a P.\nIf you want to allow only a single user on your project to access the table, you will need to grant permission to that user. You can do this by running the following code:\nGRANT SELECT, UPDATE, DELETE, INSERT ON TABLE schema_name.table_name to \"IAM:first_name.last_name.project_code\";\nNote: In the above code example replace schma_name with the pr_ or tr_ schema assigned to your workspace and replace table_name with the name of the table on which you want to grant access. Also, in \"IAM:first_name.last_name.project_code\" update first_name.last_name.project_code with the user name to whom you want to grant access to.\nIf you have any questions, please reach out to us at support@coleridgeinitiative.org\n\n\n\nConnecting to a database through a statistical program using an ODBC connection\nWhen connecting to the database using an ODBC connection, you need to use one of the following DSNs:\n\nRedshift01_projects_DSN\nRedshift11_projects_DSN\n\nIn the code examples below, the default DSN is Redshift01_projects_DSN.\nTopics: - Connecting to a database using SAS - Connecting to a database using R - Connecting to a database using Python - Connecting to a database using Stata\n\nConnecting to a database using SAS\nUse the following code to connect to a databse using SAS:\nproc sql;\nconnect to odbc as my con\n(datasrc=Redshift01_projects_DSN user=adrf\\user.name.project password=password);\nselect * from connection to mycon\n(select * form projects.schema.table);\ndisconnect from mycon;\nquit;\n\n\nConnecting to a database using R\n\nRecommended method for connecting to a database using R\nUsing Renviron file to connect to a database using R\nBest practices for loading large amounts of data in R\n\n\nRecommended method for connecting to a database using R\nNote: To use this method, you may need to install the packages RJDBC and rstudioapi first.\nlibrary(RJDBC)\n\n# Create username\ndbusr=paste(\"ADRF\\\\\", Sys.getenv(\"USERNAME\"), sep= '')                                                                                \n\n# Database URL\nurl &lt;- paste0(\"jdbc:redshift:iam://adrf-redshift01.cdy8ch2udktk.us-gov-west-1.redshift.amazonaws.com:5439/projects;\",\n              \"loginToRp=urn:amazon:webservices:govcloud;\",\n              \"ssl=true;\",\n              \"AutoCreate=true;\",\n              \"idp_host=adfs.adrf.net;\",\n              \"idp_port=443;\",\n              \"ssl_insecure=true;\",\n              \"plugin_name=com.amazon.redshift.plugin.AdfsCredentialsProvider\")\n\n# Redshift JDBC Driver Setting\ndriver &lt;- JDBC(\"com.amazon.redshift.jdbc42.Driver\",\n               classPath = \"C:\\\\drivers\\\\redshift_withsdk\\\\redshift-jdbc42-2.1.0.12\\\\redshift-jdbc42-2.1.0.12.jar\",\n               identifier.quote=\"`\")\ncon &lt;- dbConnect(driver, url, dbusr, rstudioapi::askForPassword())\n\n\nUsing Renviron file to connect to a database using R\nlibrary(RJDBC)\ndbusr=Sys.getenv(\"DBUSER\")                                                                    dbpswd=Sys.getenv(\"DBPASSWD\")\n\n# Database URL\nurl &lt;- paste0(\"jdbc:redshift:iam://adrf-redshift01.cdy8ch2udktk.us-gov-west-1.redshift.amazonaws.com:5439/projects;\",\n\"loginToRp=urn:amazon:webservices:govcloud;\",\n\"ssl=true;\",\n\"AutoCreate=true;\",\n\"idp_host=adfs.adrf.net;\",\n\"idp_port=443;\",\n\"ssl_insecure=true;\",\n\"plugin_name=com.amazon.redshift.plugin.AdfsCredentialsProvider\")\n\n# Redshift JDBC Driver Setting\ndriver &lt;- JDBC(\"com.amazon.redshift.jdbc42.Driver\",\nclassPath = \"C:\\\\drivers\\\\redshift_withsdk\\\\redshift-jdbc42-2.1.0.12\\\\redshift-jdbc42-2.1.0.12.jar\",\nidentifier.quote=\"`\")\nconn &lt;- dbConnect(driver, url, dbusr, dbpswd)\nNote: For the above code to work, please create a file name .Renviron in your user folder (user folder is something like i.e. u:\\John.doe.p00002) And .Renviron file should contain the following:\nDBUSER='adrf\\John.doe.p00002'\nDBPASSWD='xxxxxxxxxxxx'\n_PLEASE replace user id and password with your project workspace specific user id and password.\nThis will ensure you don’t have your id and password in R code and then you can easily share your R code with others without sharing your ID and password._\n\n\nBest practices for loading large amounts of data in R\n\n\nSQL Basics with R Programming\nTo ensure R can efficiently manage large amounts of data, please add the following lines of code to your R script before any packages are loaded:\noptions(java.parameters = c(\"-XX:+UseConcMarkSweepGC\", \"-Xmx8192m\"))\ngc()\n\n\nBest practices for writing tables to Redshift\nWhen writing an R data frame to Redshift use the following code as an example:\n# Note: replace the table_name with the name of the data frame you wish to write to Redshift\n\nDBI::dbWriteTable(conn = conn, #name of the connection \nname = \"schema_name.table_name\", #name of table to save df to \nvalue = df_name, #name of df to write to Redshift \noverwrite = TRUE) #if you want to overwrite a current table, otherwise FALSE\n\nqry &lt;- \"GRANT SELECT ON TABLE schema.table_name TO group &lt;group_name&gt;;\"\ndbSendUpdate(conn,qry)\n\n\n\n\nConnecting to a database using Python\nimport pyodbc\nimport pandas as pd\ncnxn = pyodbc.connect('DSN=Redshift01_projects_DSN; UID=adrf\\user.name.project; PWD=password')\ndf = pd.read_sql(\"SELECT * FROM projects.schema_name.table_name\", cnxn)\n\n\nConnecting to a database using Stata\nodbc load, exec(\"select * from PATH_TO_TABLE\") clear dsn(\"Redshift11_projects_DSN\") user(\"adrf\\user.name.project\") password(\"password\")",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>ADRF User Guide</span>"
    ]
  },
  {
    "objectID": "dev-document.html#accessing-adrf-dashboards",
    "href": "dev-document.html#accessing-adrf-dashboards",
    "title": "16  ADRF User Guide",
    "section": "12 Accessing ADRF Dashboards",
    "text": "12 Accessing ADRF Dashboards\nSome users will be approved to access an ADRF Dashboard. This section provides step-by-step instructions for accessing ADRF Dashboards.\nNote: If you are a first-time ADRF Users, please follow the instructions in the Onboarding Modules and Security Training to activate your ADRF account and complete your onboarding tasks.\n\nStep 1: Setting your dashboard access password\nOnce you have completed the management portal onboarding tasks, you will next need to set your dashboard access password. This is separate from the first password you use to access the ADRF through Okta, and will instead be used to provide specific access to the dashboard. You should only need to do this the first time you access the dashboard, but you can always follow these instructions if you need to update or reset your dashboard access password in the future.\n\nIn the Management Portal, again navigate to the “Admin Tasks” page by clicking the link on the sidebar navigation menu:\n\n\n\n\nAdmin Tasks\n\n\n\nClick on the “Reset Password” button:\n\n\n\n\nClick on Reset Password\n\n\n\nThis will load the password reset window:\n\n\n\n\nThis will load the password reset window\n\n\n\nSelect the account associated with the dashboard by clicking on the checkbox on the right:\n\n\n\n\nSelect account\n\n\nImportant: Take note of the username associated with your dashboard (John.Doe.P00000 in this example). You will need to enter this username again in the next step. This is also the user name referenced in your onboarding email.\n\nEnter the desired password. The chosen password must adhere to the ADRF password policy:\n\n\n\n\nEnter new password\n\n\n\nClick the “Reset Password” button to proceed with the update. You will receive confirmation at the bottom of the window once the password has been successfully updated:\n\n\n\n\nReset password\n\n\n\n\nStep 2: Accessing the Dashboard\nOnce you have successfully reset your dashboard access password, you are ready to access the dashboard. To do so, navigate back to the main Okta portal (adrf.okta.com) and click on the tile associated with your dashboard. This tile will be unavailable until you complete the three ADRF onboarding tasks discussed in Onboarding Modules and Security Training:\n\n\n\nYour Dashboard\n\n\nClicking on this will bring up another window where you will be prompted to “Choose Your Application to Get Started.” Click on your Dashboard icon:\n\n\n\nChoose your application to get started\n\n\nNext, you will need to wait for your session to be prepared. Then, your session will load the secure browser window, which will then bring up the Posit Connect portal. The Posit Connect portal is used to host the Dashboard. This step may take several seconds while the browser loads and prepares the dashboard data.\nBefore accessing the dashboard, you will then be presented with one final request to log into the secure Connect environment.:\n\n\n\nLogin to the Secure Connect Environment\n\n\nHere, please enter:\n\nThe username you saw in the Password Reset step above (e.g., John.Doe.P00000)\nYour dashboard access password that you set in Step 2.\n\n\n\n\nEnter your credentials\n\n\nOnce you enter the appropriate information and click “Log In,” your dashboard should begin to load. This again may take a minute or two - if you run into any issues, please reach out to us at support@coleridgeinitiative.org.",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>ADRF User Guide</span>"
    ]
  },
  {
    "objectID": "dev-document.html#frequently-asked-questions-faq",
    "href": "dev-document.html#frequently-asked-questions-faq",
    "title": "16  ADRF User Guide",
    "section": "13 Frequently Asked Questions (FAQ)",
    "text": "13 Frequently Asked Questions (FAQ)\n\nTopics\n\n\nHow do I set up my Multifactor Authentication\nYou should be prompted to set up multifactor authentication when you create your account, the options are SMS, voice call, email and the Okta verify application.\n\n\nCan I set up more than one form of Multifactor Authentication?\nThis is recommended. If you lose access to one form of MFA, you would still be able to gain access to your account using an alternative. To do so, please log on to https://adrf.okta.com and select your name on the top right and click settings. Here you can modify or set up your SMS, voice call, email or Okta multifactor authentication.\n\n\nHow can I reset my Okta password?\nYou can use the “Need help signing in?” option on the sign on page (https://adrf.okta.com) which will send a link to your email to reset your password. You may have to verify your identify by answering security questions which you set up when creating your account.\n\n\nHow can I reset my ADRF password?\nYou can reset your ADRF project password by following these steps:\n\nClick on the ADRF Management Portal Okta Tile: \nThen click on Admin Tasks on the left hand side of the screen: \nThen click on RESET PASSWORD: \n\nYou’ll see a screen where you can choose the project(s) for which you want to update the password.",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>ADRF User Guide</span>"
    ]
  },
  {
    "objectID": "dev-document.html#references",
    "href": "dev-document.html#references",
    "title": "16  ADRF User Guide",
    "section": "References",
    "text": "References",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>ADRF User Guide</span>"
    ]
  },
  {
    "objectID": "dev-document.html#footnotes",
    "href": "dev-document.html#footnotes",
    "title": "16  ADRF User Guide",
    "section": "",
    "text": "Confidential Information Protection and Statistical Efficiency Act of 2002. (Washington, DC: U.S. GPO, 2002).↩︎\nFederal Committee on Statistical Methodology. “Report on Statistical Disclosure Limitation Methodology,” 22 (Second Version, 2005). https://nces.ed.gov/fcsm/pdf/spwp22.pdf.↩︎\n“How to Use Microdata Properly: Self-Study Material for the Users of Eurostat Microdata Sets.” (2018). https://ec.europa.eu/eurostat/web/microdata/overview/self-study-material-for-microdata-users.↩︎\nResearch Data Centre of the German Federal Employment Agency at the Institute for Employment Research. “Remote Data Access and On-Site Use at the FDZ of the BA at the IAB.” (2020, December 8). http://doku.iab.de/fdz/access/Vorgaben_DAFE_EN.PDF.↩︎\nWelpton, Richard. Handbook on Statistical Disclosure Control for Outputs. (figshare, 2019). https://doi.org/10.6084/m9.figshare.9958520.v1.↩︎",
    "crumbs": [
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>ADRF User Guide</span>"
    ]
  }
]